{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re,csv,string,syllables,math,nltk,nltk.data,io,markovify,sys,getopt,os.path,random,json,gensim,requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from nltk.collocations import *\n",
    "from nltk.tokenize import word_tokenize,RegexpTokenizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "from random_word import RandomWords\n",
    "from essential_generators import DocumentGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     1,
     3
    ]
   },
   "outputs": [],
   "source": [
    "# 計算音節數量\n",
    "def count_syllables(word):\n",
    "    return len(re.findall('(?!e$)[aeiouy]+', word, re.I) + re.findall('^[^aeiouy]*e$', word, re.I))\n",
    "def syllable_count(word):\n",
    "    word = word.lower()\n",
    "    punc = string.punctuation\n",
    "    count = 0\n",
    "    vowels = \"aeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith(\"e\"):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    if word in punc: # 如果詞語是標點符號，音節數量則為0\n",
    "        count = 0\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 透過爬蟲方式找相似詞語\n",
    "def crawl_synonyms(word):\n",
    "    url = \"https://www.thesaurus.com/browse/\"\n",
    "    url += word\n",
    "    #print(url)\n",
    "    r = requests.get(url)\n",
    "    soup = bs(r.content, \"html.parser\")\n",
    "    answer_list = soup.find(\"ul\",'css-17d6qyx-WordGridLayoutBox et6tpn80')\n",
    "    syns = answer_list.findChildren(\"a\")\n",
    "    #print(syns)\n",
    "    lst = []\n",
    "    for i in range(len(syns)):\n",
    "        lst.append(syns[i].text)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     4
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "['Where', 'the', 'old', 'men', 'pray', 'His', 'children', 'lived', 'next', 'door', 'They', 'used', 'to', 'live', 'in', 'the', 'woods', 'But', 'this', \"man's\", 'religious', 'bone', 'He', \"didn't\", 'have', 'a', 'prayer', 'No', 'he', \"didn't\", 'have', 'a', 'prayer', 'He', 'just', 'said', \"I've\", 'got', 'to', 'find', 'my', 'own', 'way', 'home', 'And', \"I've\", 'got', 'to', 'find', 'my', 'own', 'way', 'home', 'If', 'I', 'can', 'do', 'the', 'things', 'he', 'says', 'That', 'I', 'just', \"can't\", 'understand', 'Then', \"I'll\", 'just', 'settle', 'down', 'and', 'start', 'living', 'for', 'today', 'Lord', 'how', \"I'd\", 'love', 'to', 'settle', 'down', 'And', 'start', 'living', 'for', 'today', 'Lord', 'how', \"I'd\", 'love', 'to', 'settle', 'down', 'But', 'I', \"don't\", 'have', 'a', 'prayer', 'I', \"don't\", 'have', 'a', 'prayer', 'No', 'I', \"don't\", 'have', 'a', 'prayer', 'Sometimes', 'I', 'think', 'of', 'what', 'a', 'wife', 'must', 'be', 'And', 'how', 'I', 'hate', 'to', 'do', 'things', 'That', 'he', \"doesn't\", 'have', 'to', 'do', 'But', 'then', 'somehow', 'I', 'think', 'of', 'what', 'hope', 'is', 'And', 'do', 'I', 'have', 'to', 'start', 'Oh', 'oh', \"I'm\", 'ready', 'to', 'begin', 'Oh', 'how', \"I'd\", 'love', 'to', 'settle', 'down', \"I'm\", 'ready', 'ready', 'ready', 'If', 'I', 'can', 'do', 'the', 'things', 'he', 'says', 'That', 'I', 'just', \"can't\", 'understand', 'Then', \"I'll\", 'just', 'settle', 'down', 'and', 'start', 'living', 'for', 'today', 'Lord', 'how', \"I'd\", 'love', 'to', 'settle', 'down', 'And', 'I', \"don't\", 'have', 'a', 'prayer', 'No', 'I', \"don't\", 'have', 'a', 'prayer', 'Always', 'always', 'start', 'the', 'day', 'Lord', 'how', \"I'd\", 'love', 'to', 'settle', 'down', \"I'm\", 'ready', 'ready', 'ready', 'If', 'I', 'can', 'do', 'the', 'things', 'he', 'says', 'That', 'I', 'just', \"can't\", 'understand', 'Then', \"I'll\", 'just', 'settle', 'down', 'and', 'start', 'living', 'for', 'today', 'Lord', 'how', \"I'd\", 'love', 'to', 'settle', 'down', 'But', 'I', \"don't\", 'have', 'a', 'prayer', 'No', 'I', \"don't\", 'have', 'a', 'prayer', 'I', \"can't\", 'do', 'the', 'things', 'he', 'says', 'That', 'I', 'just', \"can't\", 'understand', 'Then', \"I'll\", 'just', 'settle', 'down', 'and', 'start', 'living', 'for', 'today']\n"
     ]
    }
   ],
   "source": [
    "# 生成歌詞\n",
    "# 句子詞語分割\n",
    "# https://www.geeksforgeeks.org/nlp-how-tokenizing-text-sentence-words-works/\n",
    "# https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer\n",
    "gen_text = \"Where the old men pray\\\n",
    "            His children lived next door\\\n",
    "            They used to live in the woods\\\n",
    "            But this man's religious bone\\\n",
    "            He didn't have a prayer\\\n",
    "            No, he didn't have a prayer\\\n",
    "            He just said I've got to find my own way home\\\n",
    "            And I've got to find my own way home\\\n",
    "            If I can do the things he says\\\n",
    "            That I just can't understand\\\n",
    "            Then I'll just settle down and start living for today\\\n",
    "            Lord, how I'd love to settle down\\\n",
    "            And start living for today\\\n",
    "            Lord, how I'd love to settle down\\\n",
    "            But I don't have a prayer\\\n",
    "            I don't have a prayer\\\n",
    "            No, I don't have a prayer\\\n",
    "            Sometimes, I think of what a wife must be\\\n",
    "            And how I hate to do things\\\n",
    "            That he doesn't have to do\\\n",
    "            But then somehow, I think of what hope is\\\n",
    "            And do I have to start\\\n",
    "            Oh, oh, I'm ready to begin\\\n",
    "            Oh, how I'd love to settle down\\\n",
    "            I'm ready, ready, ready\\\n",
    "            If I can do the things he says\\\n",
    "            That I just can't understand\\\n",
    "            Then I'll just settle down and start living for today\\\n",
    "            Lord, how I'd love to settle down\\\n",
    "            And I don't have a prayer\\\n",
    "            No, I don't have a prayer\\\n",
    "            Always, always start the day\\\n",
    "            Lord, how I'd love to settle down\\\n",
    "            I'm ready, ready, ready\\\n",
    "            If I can do the things he says\\\n",
    "            That I just can't understand\\\n",
    "            Then I'll just settle down and start living for today\\\n",
    "            Lord, how I'd love to settle down\\\n",
    "            But I don't have a prayer No, I don't have a prayer\\\n",
    "            I can't do the things he says\\\n",
    "            That I just can't understand\\\n",
    "            Then I'll just settle down and start living for today\"\n",
    "tokenizer = RegexpTokenizer(\"[\\w']+\") \n",
    "lst_gen_tokenize = tokenizer.tokenize(gen_text)\n",
    "print(len(lst_gen_tokenize))\n",
    "print(lst_gen_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     5
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lst_gen_syllables: 288\n",
      "[1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# 計算生成歌詞的音節數量\n",
    "lst_gen_syllables = []\n",
    "count1 = []\n",
    "count2 = []\n",
    "count3 = []\n",
    "for i in range(len(lst_gen_tokenize)):\n",
    "    count_gen = syllable_count(lst_gen_tokenize[i])\n",
    "    lst_gen_syllables.append(count_gen)\n",
    "    if count_gen == 1:\n",
    "        count1.append(lst_gen_tokenize[i])\n",
    "    if count_gen == 2:\n",
    "        count2.append(lst_gen_tokenize[i])\n",
    "    if count_gen == 3:\n",
    "        count3.append(lst_gen_tokenize[i])\n",
    "print('lst_gen_syllables:',len(lst_gen_syllables))\n",
    "print(lst_gen_syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Where', 'the', 'old', 'men', 'pray', 'His', 'next', 'door', 'They', 'to', 'live', 'in', 'the', 'woods', 'But', 'this', \"man's\", 'bone', 'He', \"didn't\", 'have', 'a', 'prayer', 'No', 'he', \"didn't\", 'have', 'a', 'prayer', 'He', 'just', 'said', \"I've\", 'got', 'to', 'find', 'my', 'own', 'way', 'home', 'And', \"I've\", 'got', 'to', 'find', 'my', 'own', 'way', 'home', 'If', 'I', 'can', 'do', 'the', 'things', 'he', 'says', 'That', 'I', 'just', \"can't\", 'Then', \"I'll\", 'just', 'settle', 'down', 'and', 'start', 'for', 'Lord', 'how', \"I'd\", 'love', 'to', 'settle', 'down', 'And', 'start', 'for', 'Lord', 'how', \"I'd\", 'love', 'to', 'settle', 'down', 'But', 'I', \"don't\", 'have', 'a', 'prayer', 'I', \"don't\", 'have', 'a', 'prayer', 'No', 'I', \"don't\", 'have', 'a', 'prayer', 'I', 'think', 'of', 'what', 'a', 'wife', 'must', 'be', 'And', 'how', 'I', 'hate', 'to', 'do', 'things', 'That', 'he', \"doesn't\", 'have', 'to', 'do', 'But', 'then', 'I', 'think', 'of', 'what', 'hope', 'is', 'And', 'do', 'I', 'have', 'to', 'start', 'Oh', 'oh', \"I'm\", 'to', 'Oh', 'how', \"I'd\", 'love', 'to', 'settle', 'down', \"I'm\", 'If', 'I', 'can', 'do', 'the', 'things', 'he', 'says', 'That', 'I', 'just', \"can't\", 'Then', \"I'll\", 'just', 'settle', 'down', 'and', 'start', 'for', 'Lord', 'how', \"I'd\", 'love', 'to', 'settle', 'down', 'And', 'I', \"don't\", 'have', 'a', 'prayer', 'No', 'I', \"don't\", 'have', 'a', 'prayer', 'start', 'the', 'day', 'Lord', 'how', \"I'd\", 'love', 'to', 'settle', 'down', \"I'm\", 'If', 'I', 'can', 'do', 'the', 'things', 'he', 'says', 'That', 'I', 'just', \"can't\", 'Then', \"I'll\", 'just', 'settle', 'down', 'and', 'start', 'for', 'Lord', 'how', \"I'd\", 'love', 'to', 'settle', 'down', 'But', 'I', \"don't\", 'have', 'a', 'prayer', 'No', 'I', \"don't\", 'have', 'a', 'prayer', 'I', \"can't\", 'do', 'the', 'things', 'he', 'says', 'That', 'I', 'just', \"can't\", 'Then', \"I'll\", 'just', 'settle', 'down', 'and', 'start', 'for']\n",
      "['children', 'lived', 'used', 'living', 'today', 'living', 'today', 'ready', 'begin', 'ready', 'ready', 'ready', 'living', 'today', 'Always', 'always', 'ready', 'ready', 'ready', 'living', 'today', 'living', 'today']\n",
      "['religious', 'understand', 'somehow', 'understand', 'understand', 'understand']\n"
     ]
    }
   ],
   "source": [
    "print(count1)\n",
    "print(count2)\n",
    "print(count3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277\n",
      "[\"I'll\", 'let', 'you', 'show', 'me', 'his', 'moves', 'Let', 'you', 'do', 'what', 'he', 'taught', 'you', 'Let', 'you', 'reminisce', 'how', 'you', 'used', 'to', 'do', 'Girl', 'I', 'm', 'open', 'to', 'anything', \"that'll\", 'get', 'you', 'into', 'that', 'zone', 'And', 'understand', 'that', 'we', 're', 'all', 'alone', 'So', 'you', 'can', 'slowly', 'take', 'off', 'your', 'clothes', 'Baby', 'girl', 'you', 'know', \"what's\", 'in', 'store', 'And', 'baby', 'I', 'will', 'stay', 'up', 'all', 'night', \"I've\", 'been', \"goin'\", 'hard', 'since', 'last', 'night', 'And', \"I'mma\", 'go', 'harder', 'tonight', 'Wish', 'you', 'could', 'see', 'you', 'through', 'my', 'eyes', 'Ooh', \"I'm\", 'telling', 'you', 'this', \"ain't\", 'the', 'same', 'And', 'I', 'know', \"he's\", 'still', 'in', 'your', 'brain', \"I'm\", \"'bout\", 'to', 'burn', 'that', 'shit', 'into', 'flames', 'Once', \"I'm\", 'in', 'you', 'Baby', 'Forget', 'what', 'you', 'know', 'Make', 'yourself', 'at', 'home', \"'Cuz\", 'baby', 'when', \"I'm\", 'finished', 'with', 'ya', 'you', \"won't\", 'wanna', 'go', 'Outside', 'And', \"I'mma\", 'work', 'you', 'like', 'a', 'pro', 'baby', 'And', 'you', \"gon'\", 'take', 'it', 'like', 'one', 'Yeah', 'you', \"gon'\", 'take', 'it', 'like', 'one', 'And', \"I'mma\", 'give', 'it', 'like', 'you', 'asked', 'for', 'it', 'Why', 'cuz', 'you', 'been', \"talkin'\", \"'bout\", 'it', 'I', 'know', 'you', 'been', \"talkin'\", \"'bout\", 'it', 'Ooh', 'baby', 'when', \"I'm\", 'done', 'with', 'you', 'You', \"ain't\", 'saying', 'nothing', 'Yeah', 'you', \"ain't\", 'saying', 'nothing', 'Ooh', 'baby', 'when', \"I'm\", 'done', 'with', 'you', 'You', \"ain't\", 'saying', 'nothing', 'Yeah', 'you', \"ain't\", 'saying', 'nothing', 'You', \"gon'\", 'make', 'me', 'show', 'off', 'All', 'the', 'pain', 'that', 'you', 'feel', 'you', 'can', 'tell', 'that', 'we', \"ain't\", 'making', 'no', 'love', 'But', \"I'll\", 'pretend', 'Oh', 'girl', \"I'll\", 'pretend', 'If', 'you', 'pretend', 'then', 'girl', \"I'll\", 'pretend', \"Let's\", 'make', 'it', 'seem', 'like', \"we're\", 'all', 'we', 'need', 'in', 'the', 'end', 'Forget', 'what', 'you', 'know', 'Make', 'yourself', 'at', 'home', \"'Cuz\", 'baby', 'when', \"I'm\", 'finished', 'with', 'ya', 'you', \"won't\", 'wanna', 'go', 'Outside']\n"
     ]
    }
   ],
   "source": [
    "# 原始歌詞\n",
    "ori_text = \"I'll let you show me his moves\\\n",
    "            Let you do what he taught you\\\n",
    "            Let you reminisce how you used, to do\\\n",
    "            Girl I?m open to anything that'll get you into that zone\\\n",
    "            And understand that we?re all alone\\\n",
    "            So you can slowly take off your clothes\\\n",
    "            Baby girl you know what's in store\\\n",
    "            And baby I will stay up all night\\\n",
    "            I've been goin' hard since last night\\\n",
    "            And I'mma go harder tonight\\\n",
    "            Wish you could see you through my eyes\\\n",
    "            Ooh I'm telling you this ain't the same\\\n",
    "            And I know he's still in your brain\\\n",
    "            I'm 'bout to burn that shit into flames\\\n",
    "            Once I'm in you\\\n",
    "            Baby\\\n",
    "            Forget what you know\\\n",
    "            Make yourself at home\\\n",
    "            'Cuz baby when I'm finished with ya you won't wanna go Outside\\\n",
    "            And I'mma work you like a pro, baby\\\n",
    "            And, you gon' take it like one\\\n",
    "            Yeah you gon' take it like one\\\n",
    "            And I'mma give it like you asked for it\\\n",
    "            Why, cuz you been talkin' 'bout it\\\n",
    "            I know you been talkin' 'bout it\\\n",
    "            Ooh baby when I'm done with you\\\n",
    "            You ain't saying nothing\\\n",
    "            Yeah you ain't saying nothing\\\n",
    "            Ooh baby when I'm done with you\\\n",
    "            You ain't saying nothing\\\n",
    "            Yeah you ain't saying nothing\\\n",
    "            You gon' make me show off\\\n",
    "            All the pain that you feel you can tell that we ain't making no love\\\n",
    "            But I'll pretend\\\n",
    "            Oh girl, I'll pretend\\\n",
    "            If you pretend then girl I'll pretend\\\n",
    "            Let's make it seem like we're all we need in the end\\\n",
    "            Forget what you know\\\n",
    "            Make yourself at home\\\n",
    "            'Cuz baby when I'm finished with ya you won't wanna go Outside\"\n",
    "tokenizer = RegexpTokenizer(\"[\\w']+\") \n",
    "lst_ori_tokenize = tokenizer.tokenize(ori_text)\n",
    "print(len(lst_ori_tokenize))\n",
    "print(lst_ori_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277\n",
      "[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# 計算原始歌詞的音節數量\n",
    "lst_ori_syllables = []\n",
    "for i in range(len(lst_ori_tokenize)):\n",
    "    count_ori = syllable_count(lst_ori_tokenize[i])\n",
    "    lst_ori_syllables.append(count_ori)\n",
    "print(len(lst_ori_syllables))\n",
    "print(lst_ori_syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     14,
     20
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n",
      "64\n",
      "tmp_wo: 277\n",
      "['', '', '', '', '', '', '', 'lived', '', '', '', 'used', '', '', '', '', 'woods', '', '', \"man's\", 'religious', '', '', '', '', 'a', '', 'No', '', '', '', 'a', '', '', '', 'said', '', '', '', '', 'my', '', '', '', 'And', '', '', '', 'find', 'my', '', '', '', '', '', '', '', 'the', '', '', '', '', '', '', '', 'understand', '', '', '', '', '', '', 'start', 'living', 'for', '', '', '', '', '', '', '', '', '', '', 'living', 'for', 'today', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'No', 'I', '', '', '', '', 'Sometimes', 'I', '', '', '', '', 'wife', '', '', '', 'how', '', '', 'to', '', '', '', '', \"doesn't\", '', 'to', '', 'But', '', 'somehow', '', '', '', 'what', '', '', '', '', '', '', '', '', '', '', '', 'ready', '', 'begin', '', 'how', '', '', '', '', 'down', '', 'ready', 'ready', 'ready', '', '', 'can', '', '', '', '', '', '', 'I', '', '', 'understand', 'Then', '', '', '', '', '', '', 'living', '', '', '', '', '', '', 'to', '', 'down', '', '', '', '', '', '', '', '', \"don't\", '', '', '', 'Always', '', '', '', '', '', '', '', '', '', '', '', '', 'ready', 'ready', 'ready', '', '', '', '', 'the', '', '', '', '', 'I', '', '', 'understand', 'Then', '', '', 'settle', '', '', '', '', '', 'today', '', '', '', '', '', '', '', '', '', '', 'have', '', '', '', '', \"don't\", '', '', '', 'I', '', '', 'the', '', '', '', '', 'I', '', \"can't\"]\n",
      "tmp_so: 277\n",
      "['', '', '', '', '', '', '', 1, '', '', '', 1, '', '', '', '', 3, '', '', 2, 1, '', '', '', '', 2, '', 3, '', '', '', 2, '', '', '', 3, '', '', '', '', 2, '', '', '', 2, '', '', '', 2, 2, '', '', '', '', '', '', '', 2, '', '', '', '', '', '', '', 1, '', '', '', '', '', '', 2, 1, 2, '', '', '', '', '', '', '', '', '', '', 1, 2, 1, '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 2, 2, '', '', '', '', 2, 2, '', '', '', '', 2, '', '', '', 2, '', '', 3, '', '', '', '', 2, '', 2, '', 2, '', 1, '', '', '', 2, '', '', '', '', '', '', '', '', '', '', '', 1, '', 1, '', 2, '', '', '', '', 2, '', 1, 1, 1, '', '', 2, '', '', '', '', '', '', 2, '', '', 1, 2, '', '', '', '', '', '', 1, '', '', '', '', '', '', 2, '', 2, '', '', '', '', '', '', '', '', 2, '', '', '', 1, '', '', '', '', '', '', '', '', '', '', '', '', 1, 1, 1, '', '', '', '', 2, '', '', '', '', 2, '', '', 1, 2, '', '', 2, '', '', '', '', '', 1, '', '', '', '', '', '', '', '', '', '', 2, '', '', '', '', 2, '', '', '', 2, '', '', 3, '', '', '', '', 2, '', 2]\n"
     ]
    }
   ],
   "source": [
    "# 比對兩個音節個數陣列(gen長度>ori長度)\n",
    "len_g = len(lst_gen_syllables)\n",
    "len_o = len(lst_ori_syllables)\n",
    "if len_g > len_o:\n",
    "    lst_gen_syllables2 = lst_gen_syllables[:len_g-(len_g-len_o)]\n",
    "# print('lst_gen_syllables2:',len(lst_gen_syllables2))\n",
    "# print(lst_gen_syllables2)\n",
    "correct = 0\n",
    "wrong = 0\n",
    "tmp_w = []\n",
    "tmp_wo = []\n",
    "tmp_s = []\n",
    "tmp_so = []\n",
    "for j in range(len(lst_gen_syllables2)):\n",
    "    if lst_gen_syllables[j] == lst_ori_syllables[j]:\n",
    "        tmp_w.append(lst_gen_tokenize[j])\n",
    "        tmp_wo.append('')\n",
    "        tmp_s.append(lst_gen_syllables[j])\n",
    "        tmp_so.append('')\n",
    "        correct += 1\n",
    "    else:\n",
    "        tmp_w.append('')\n",
    "        tmp_wo.append(lst_gen_tokenize[j]) # 生成的詞語對不上原始歌詞的音節\n",
    "        tmp_s.append('')\n",
    "        tmp_so.append(lst_ori_syllables[j]) # 正確的音節數\n",
    "        wrong += 1\n",
    "print(correct)\n",
    "print(wrong)\n",
    "#print('tmp_w:',len(tmp_w)) # 有對齊的生成詞語\n",
    "#print(tmp_w)\n",
    "print('tmp_wo:',len(tmp_wo)) # 沒對齊的生成詞語\n",
    "print(tmp_wo)\n",
    "#print('tmp_s:',len(tmp_s)) # 有對齊的生成詞語音節數量\n",
    "#print(tmp_s)\n",
    "print('tmp_so:',len(tmp_so)) # 沒對齊的(取原始歌詞詞語應有的音節數量)\n",
    "print(tmp_so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original word: religious\n",
      "synonyms list: ['spiritual', 'religious']\n",
      "correct syllable count: 1\n",
      "[]\n",
      "clerical\n"
     ]
    }
   ],
   "source": [
    "# 測試用：搜尋詞語的同義詞(使用NLTK)\n",
    "#nltk.download('wordnet')\n",
    "num = 20\n",
    "synonyms = []\n",
    "word = tmp_wo[num]\n",
    "try:\n",
    "    syns = wordnet.synsets(word)[0].name()\n",
    "except:\n",
    "    word = preprocessText2(word) # 對詞語預處理\n",
    "    syns = wordnet.synsets(word)[0].name()\n",
    "print('original word:',word)\n",
    "for syn in wordnet.synsets(word): # pos可指定詞性,pos='a'\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "synonyms2 = list(set(synonyms))\n",
    "print('synonyms list:',synonyms2) # 用set()把重複的去除掉\n",
    "\n",
    "s = tmp_so[num] # 正確的音節數量\n",
    "print('correct syllable count:',s)\n",
    "match_word = []\n",
    "for n in range(len(synonyms2)):\n",
    "    if syllable_count(synonyms2[n]) == s: # 列出符合音節數的同義詞\n",
    "        print(synonyms2[n],syllable_count(synonyms2[n]))\n",
    "        match_word.append(synonyms2[n])\n",
    "print(match_word)\n",
    "if len(match_word) == 0:\n",
    "    crawl = crawl_synonyms(tmp_wo[num])\n",
    "    print(crawl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original word: lived\n",
      "synonyms list: ['live', 'last', 'endure', 'subsist', 'dwell', 'survive', 'exist', 'know', 'inhabit', 'hold_up', 'hold_out', 'go', 'be', 'experience', 'populate', 'live_on']\n",
      "correct syllable count: 1\n",
      "match word: live\n",
      "----------------------------------------------------------------------\n",
      "original word: used\n",
      "synonyms list: ['victimized', 'ill-used', 'put-upon', 'employ', 'exploited', 'apply', 'use', 'habituate', 'secondhand', 'used', 'utilize', 'expend', 'utilise', 'practice', 'victimised']\n",
      "correct syllable count: 1\n",
      "match word: use\n",
      "----------------------------------------------------------------------\n",
      "original word: woods\n",
      "synonyms list: ['Natalie_Wood', 'woodwind_instrument', 'Ellen_Price_Wood', 'woodwind', 'woods', 'Sir_Henry_Joseph_Wood', 'Grant_Wood', 'wood', 'forest', 'Wood', 'Sir_Henry_Wood', 'Mrs._Henry_Wood']\n",
      "correct syllable count: 3\n",
      "match word: Mrs._Henry_Wood\n",
      "----------------------------------------------------------------------\n",
      "original word: mans\n",
      "synonyms list: ['military_personnel', 'human_beings', 'man', 'adult_male', 'piece', 'world', 'humanity', 'mankind', 'homo', 'humans', 'human_being', 'Isle_of_Man', 'gentleman', 'military_man', 'human', 'serviceman', \"gentleman's_gentleman\", 'Man', 'valet_de_chambre', 'humankind', 'human_race', 'valet']\n",
      "correct syllable count: 2\n",
      "match word: mankind\n",
      "----------------------------------------------------------------------\n",
      "original word: religious\n",
      "synonyms list: ['spiritual', 'religious']\n",
      "correct syllable count: 1\n",
      "match word: clerical\n",
      "----------------------------------------------------------------------\n",
      "original word: a\n",
      "synonyms list: ['type_A', 'angstrom_unit', 'group_A', 'vitamin_A', 'ampere', 'deoxyadenosine_monophosphate', 'adenine', 'a', 'amp', 'axerophthol', 'A', 'angstrom', 'antiophthalmic_factor']\n",
      "correct syllable count: 2\n",
      "match word: group_A\n",
      "----------------------------------------------------------------------\n",
      "original word: No\n",
      "synonyms list: ['nobelium', 'no', 'atomic_number_102', 'no_more', 'No']\n",
      "correct syllable count: 3\n",
      "match word: nobelium\n",
      "----------------------------------------------------------------------\n",
      "original word: a\n",
      "synonyms list: ['type_A', 'angstrom_unit', 'group_A', 'vitamin_A', 'ampere', 'deoxyadenosine_monophosphate', 'adenine', 'a', 'amp', 'axerophthol', 'A', 'angstrom', 'antiophthalmic_factor']\n",
      "correct syllable count: 2\n",
      "match word: group_A\n",
      "----------------------------------------------------------------------\n",
      "original word: said\n",
      "synonyms list: ['tell', 'say', 'sound_out', 'enounce', 'pronounce', 'order', 'aforementioned', 'suppose', 'enunciate', 'aver', 'said', 'state', 'articulate', 'read', 'allege', 'enjoin', 'aforesaid']\n",
      "correct syllable count: 3\n",
      "match word: enunciate\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-bc8368d06b8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0msyns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-bc8368d06b8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessText2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 對詞語預處理\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0msyns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'original word:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msyn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# pos可指定詞性,pos='a'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 搜尋詞語的同義詞(使用NLTK)，並更新list(lst_rewrite)\n",
    "lst_rewrite = []\n",
    "for num in range(len(tmp_wo)): # len(tmp_wo)\n",
    "    synonyms = []\n",
    "    word = tmp_wo[num]\n",
    "    if word != '':\n",
    "        try:\n",
    "            syns = wordnet.synsets(word)[0].name()\n",
    "        except:\n",
    "            word = preprocessText2(word) # 對詞語預處理\n",
    "            syns = wordnet.synsets(word)[0].name()\n",
    "        print('original word:',word)\n",
    "        for syn in wordnet.synsets(word): # pos可指定詞性,pos='a'\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name())\n",
    "        synonyms2 = list(set(synonyms))\n",
    "        print('synonyms list:',synonyms2) # 用set()把重複的去除掉\n",
    "\n",
    "        s = tmp_so[num] # 正確的音節數量\n",
    "        print('correct syllable count:',s)\n",
    "        match_word = []\n",
    "        for n in range(len(synonyms2)):\n",
    "            if syllable_count(synonyms2[n]) == s: # 列出符合音節數的同義詞\n",
    "                #print(synonyms2[n],syllable_count(synonyms2[n]))\n",
    "                match_word.append(synonyms2[n])\n",
    "        if len(match_word) != 0: # 用wordnet方法找的到同義詞(match_word陣列長度不為0)\n",
    "            print('match word:',match_word[0])\n",
    "            lst_rewrite.append(match_word[0])\n",
    "        else: # 方法一(wordnet方法)找不到同義詞，採用第二種方法抓取同義詞(def crawl_synonyms)\n",
    "            crawl = crawl_synonyms(tmp_wo[num])\n",
    "            print('match word:',crawl[0])\n",
    "            lst_rewrite.append(crawl[0])\n",
    "        print('-'*70)\n",
    "    else:\n",
    "        lst_rewrite.append('')\n",
    "print(len(lst_rewrite))   \n",
    "print(lst_rewrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# 對歌詞的文本預處理\n",
    "def preprocessText(text, remove_stops=False):\n",
    "    \n",
    "    # 移除中括號'[]'的內容\n",
    "    text = re.sub(pattern=\"\\[.+?\\]( )?\", repl='', string=text)\n",
    "\n",
    "    # Change \"walkin'\" to \"walking\"\n",
    "    text = re.sub(pattern=\"n\\\\\\' \", repl='ng ', string=text)\n",
    "\n",
    "    # 移除小括號'()'，如：x4 → (x4)\n",
    "    text = re.sub(pattern=\"(\\()?x\\d+(\\))?\", repl=' ', string=text)\n",
    "\n",
    "    # 修正單引號\n",
    "    text = re.sub(pattern=\"\\\\x91\", repl=\"'\", string=text) # \\x保留字符\n",
    "    text = re.sub(pattern=\"\\\\x92\", repl=\"'\", string=text)\n",
    "    text = re.sub(pattern=\"<u\\+0092>\", repl=\"'\", string=text)\n",
    "    \n",
    "    # 傳化成小寫\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 處理特殊字詞用法\n",
    "    text = re.sub(pattern=\"'til\", repl=\"til\", string=text)\n",
    "    text = re.sub(pattern=\"'til\", repl=\"til\", string=text)\n",
    "    text = re.sub(pattern=\"gon'\", repl=\"gon\", string=text)\n",
    "\n",
    "    # 處理開頭的換行符號'\\n'\n",
    "    text = re.sub(pattern='^\\n', repl='', string=text)\n",
    "\n",
    "    # 移除「,」、「!」、「?」、「,」、「\\n」\n",
    "    text = ''.join([char.strip(\",!?:\") for char in text])\n",
    "    text = text.replace('\\n', ' ')\n",
    "\n",
    "    # 處理英文縮寫(特定)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"won\\’t\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    text = re.sub(r\"can\\’t\", \"can not\", text)\n",
    "    text = re.sub(r\"let's\", \"let us\", text)\n",
    "    text = re.sub(r\"let\\’s\", \"let us\", text)\n",
    "    text = re.sub(r\"ain't\", \"aint\", text)\n",
    "    text = re.sub(r\"ain\\’t\", \"aint\", text)\n",
    "\n",
    "    # 處理英文縮寫(通用)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"n\\’t\", \" not\", text)\n",
    "    text = re.sub(r\"\\’re\", \" are\", text)\n",
    "    text = re.sub(r\"\\’s\", \" is\", text)\n",
    "    text = re.sub(r\"\\’d\", \" would\", text)\n",
    "    text = re.sub(r\"\\’ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\’t\", \" not\", text)\n",
    "    text = re.sub(r\"\\’ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\’m\", \" am\", text)\n",
    "\n",
    "    # 移除剩餘的標點符號\n",
    "    punc = string.punctuation\n",
    "    text = ''.join([char for char in text if char not in punc])\n",
    "\n",
    "    # 移除停用詞\n",
    "    if remove_stops:\n",
    "        stops = stopwords.words('english')\n",
    "        text = ' '.join([word for word in text.split(' ') if word not in stops])\n",
    "    \n",
    "    # 刪除雙空格和開始結尾空格\n",
    "    text = re.sub(pattern='( ){2,}', repl=' ', string=text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'where the old men pray his children lived next door they used to live in the woods but this man is religious bone he did not have a prayer no he did not have a prayer he just said i have got to find my own way home and i have got to find my own way home if i can do the things he says that i just can not understand then i will just settle down and start living for today lord how i would love to settle down and start living for today lord how i would love to settle down but i do not have a prayer i do not have a prayer no i do not have a prayer sometimes i think of what a wife must be and how i hate to do things that he does not have to do but then somehow i think of what hope is and do i have to start oh oh i am ready to begin oh how i would love to settle down i am ready ready ready if i can do the things he says that i just can not understand then i will just settle down and start living for today lord how i would love to settle down and i do not have a prayer no i do not have a prayer always always start the day lord how i would love to settle down i am ready ready ready if i can do the things he says that i just can not understand then i will just settle down and start living for today lord how i would love to settle down but i do not have a prayer no i do not have a prayer i can not do the things he says that i just can not understand then i will just settle down and start living for today'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessText(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# 對歌詞的文本預處理版本2\n",
    "def preprocessText2(text, remove_stops=False):\n",
    "    \n",
    "    # 移除中括號'[]'的內容\n",
    "    text = re.sub(pattern=\"\\[.+?\\]( )?\", repl='', string=text)\n",
    "\n",
    "    # Change \"walkin'\" to \"walking\"\n",
    "    text = re.sub(pattern=\"n\\\\\\' \", repl='ng ', string=text)\n",
    "\n",
    "    # 移除小括號'()'，如：x4 → (x4)\n",
    "    text = re.sub(pattern=\"(\\()?x\\d+(\\))?\", repl=' ', string=text)\n",
    "\n",
    "    # 修正單引號\n",
    "    text = re.sub(pattern=\"\\\\x91\", repl=\"'\", string=text) # \\x保留字符\n",
    "    text = re.sub(pattern=\"\\\\x92\", repl=\"'\", string=text)\n",
    "    text = re.sub(pattern=\"<u\\+0092>\", repl=\"'\", string=text)\n",
    "    \n",
    "    # 傳化成小寫\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 處理特殊字詞用法\n",
    "    text = re.sub(pattern=\"'til\", repl=\"til\", string=text)\n",
    "    text = re.sub(pattern=\"'til\", repl=\"til\", string=text)\n",
    "    text = re.sub(pattern=\"gon'\", repl=\"gon\", string=text)\n",
    "\n",
    "    # 處理開頭的換行符號'\\n'\n",
    "    text = re.sub(pattern='^\\n', repl='', string=text)\n",
    "\n",
    "    # 移除「,」、「!」、「?」、「,」、「\\n」\n",
    "    text = ''.join([char.strip(\",!?:\") for char in text])\n",
    "    text = text.replace('\\n', ' ')\n",
    "\n",
    "    # 移除剩餘的標點符號\n",
    "    punc = string.punctuation\n",
    "    text = ''.join([char for char in text if char not in punc])\n",
    "\n",
    "    # 移除停用詞\n",
    "    if remove_stops:\n",
    "        stops = stopwords.words('english')\n",
    "        text = ' '.join([word for word in text.split(' ') if word not in stops])\n",
    "    \n",
    "    # 刪除雙空格和開始結尾空格\n",
    "    text = re.sub(pattern='( ){2,}', repl=' ', string=text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mans'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessText2(\"man's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"word\": \"cognoscitive\", \"definations\": [{\"source\": \"century\", \"text\": \"Having the power of knowing; cognitive.\", \"note\": null, \"partOfSpeech\": \"adjective\"}]}'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 隨機產生英文詞語\n",
    "r = RandomWords()\n",
    "# Return a single random word\n",
    "#r.get_random_word()\n",
    "# Return list of Random words\n",
    "#r.get_random_words()\n",
    "# Return Word of the day\n",
    "r.word_of_the_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "code_folding": [
     8,
     15,
     20
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opic\n",
      "Xiqalpef\n",
      "Ojpor\n",
      "Cakpofom\n",
      "Jotekwo\n",
      "Xumuq\n",
      "Osfupsar\n",
      "Weqo\n",
      "Vaamik\n",
      "Irivvo\n",
      "Cuspavey\n",
      "Besna\n",
      "Buvucki\n",
      "Igak\n",
      "Qahet\n",
      "Agogpe\n",
      "Avkooh\n",
      "Xezibqe\n",
      "Fahyud\n",
      "Bijzuhig\n",
      "Ditzu\n",
      "Uwoxok\n",
      "Xudle\n",
      "Vaobeg\n",
      "Weahgif\n",
      "Uvsina\n",
      "Kesof\n",
      "Urhewniz\n",
      "Cavegi\n",
      "Nodzuluh\n",
      "Uyxec\n",
      "Hixeik\n",
      "Ugnepeq\n",
      "Buhay\n",
      "Oqluju\n",
      "Qufe\n",
      "Islafxab\n",
      "Utdoli\n",
      "Ibvoip\n",
      "Ogje\n",
      "Muzurop\n",
      "Ejuyfa\n",
      "Wokim\n",
      "Sugebbe\n",
      "Ivyub\n",
      "Ecufwis\n",
      "Eyacur\n",
      "Efjon\n",
      "Modkikoh\n",
      "Qayufit\n"
     ]
    }
   ],
   "source": [
    "# 隨機產生英文詞語2\n",
    "vowels = list('aeiou')\n",
    "def gen_word(min, max):\n",
    "    word = ''\n",
    "    syllables = min + int(random.random() * (max - min))\n",
    "    for i in range(0, syllables):\n",
    "        word += gen_syllable()\n",
    "    return word.capitalize()\n",
    "def gen_syllable():\n",
    "    ran = random.random()\n",
    "    if ran < 0.333:\n",
    "        return word_part('v') + word_part('c')\n",
    "    if ran < 0.666:\n",
    "        return word_part('c') + word_part('v')\n",
    "    return word_part('c') + word_part('v') + word_part('c')\n",
    "def word_part(type):\n",
    "    if type is 'c':\n",
    "        return random.sample([ch for ch in list(string.ascii_lowercase) if ch not in vowels], 1)[0]\n",
    "    if type is 'v':\n",
    "        return random.sample(vowels, 1)[0]\n",
    "for i in range(0, 50):\n",
    "    print(gen_word(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1524 (total) / 6 (type) / 709 (s1) / 493 (s2) / 227 (s3) / 79 (s4) / 15 (s5) / 1 (s6)\n",
      "s1 = ['people', 'way', 'art', 'world', 'map', 'two', 'health', 'meat', 'year', 'thanks', 'food', 'law', 'bird', 'love', 'science', 'fact', 'thing', 'player', 'week', 'movie', 'thought', 'child', 'month', 'truth', 'goal', 'news', 'growth', 'night', 'disk', 'road', 'role', 'soup', 'math', 'wood', 'flight', 'length', 'cell', 'lake', 'phone', 'scene', 'death', 'mood', 'blood', 'skill', 'wealth', 'depth', 'heart', 'ad', 'debt', 'loss', 'steak', 'seat', 'match', 'bread', 'employee', 'guest', 'height', 'mall', 'sample', 'mom', 'church', 'coffee', 'hair', 'lab', 'mode', 'mud', 'queen', 'song', 'tooth', 'town', 'wife', 'gate', 'girl', 'hall', 'meal', 'pie', 'poem', 'son', 'speech', 'tea', 'breath', 'buyer', 'chest', 'cookie', 'dad', 'desk', 'king', 'tongue', 'apple', 'beer', 'cheek', 'client', 'dirt', 'ear', 'gene', 'hat', 'poet', 'shirt', 'sir', 'tale', 'throat', 'uncle', 'youth', 'time', 'work', 'film', 'while', 'game', 'life', 'form', 'air', 'day', 'place', 'part', 'field', 'fish', 'back', 'heat', 'hand', 'job', 'book', 'end', 'point', 'type', 'home', 'value', 'guide', 'state', 'course', 'price', 'size', 'card', 'list', 'mind', 'trade', 'line', 'care', 'group', 'risk', 'word', 'fat', 'force', 'key', 'light', 'name', 'school', 'top', 'sense', 'piece', 'web', 'boss', 'sport', 'fun', 'house', 'page', 'term', 'test', 'sound', 'kind', 'soil', 'board', 'oil', 'range', 'rate', 'site', 'case', 'cause', 'coast', 'age', 'bad', 'boat', 'mouse', 'cash', 'class', 'plan', 'store', 'tax', 'side', 'space', 'rule', 'stock', 'chance', 'man', 'source', 'earth', 'head', 'rock', 'salt', 'act', 'birth', 'car', 'dog', 'scale', 'sun', 'note', 'rent', 'speed', 'style', 'war', 'bank', 'craft', 'half', 'bus', 'eye', 'fire', 'stress', 'box', 'frame', 'issue', 'step', 'cycle', 'face', 'paint', 'room', 'screen', 'view', 'ball', 'share', 'bit', 'black', 'choice', 'gift', 'shape', 'tool', 'wind', 'pot', 'sign', 'table', 'task', 'egg', 'hope', 'ice', 'north', 'square', 'date', 'link', 'post', 'star', 'voice', 'friend', 'self', 'shot', 'brush', 'couple', 'front', 'lack', 'plant', 'spot', 'taste', 'theme', 'track', 'wing', 'brain', 'click', 'foot', 'gas', 'rain', 'wall', 'base', 'pair', 'staff', 'text', 'file', 'ground', 'phase', 'sky', 'stage', 'stick', 'title', 'trouble', 'bowl', 'bridge', 'club', 'edge', 'fan', 'lock', 'pack', 'park', 'skin', 'sort', 'weight', 'dish', 'fruit', 'glass', 'joint', 'muscle', 'red', 'strength', 'trip', 'chart', 'gear', 'land', 'log', 'net', 'sale', 'street', 'tree', 'wave', 'belt', 'bench', 'drop', 'path', 'sea', 'south', 'stuff', 'tour', 'angle', 'blue', 'degree', 'dot', 'dream', 'fee', 'hour', 'juice', 'luck', 'milk', 'mouth', 'peace', 'pipe', 'stable', 'storm', 'team', 'trick', 'bat', 'beach', 'blank', 'catch', 'chain', 'cream', 'crew', 'gold', 'kid', 'mark', 'pain', 'score', 'screw', 'sex', 'shop', 'suit', 'tone', 'band', 'bath', 'block', 'bone', 'cap', 'coat', 'court', 'cup', 'door', 'east', 'hole', 'hook', 'layer', 'lie', 'nose', 'rice', 'tip', 'bag', 'battle', 'bed', 'bill', 'cake', 'code', 'curve', 'dress', 'ease', 'farm', 'fight', 'gap', 'grade', 'horse', 'host', 'loan', 'nail', 'noise', 'pause', 'phrase', 'proof', 'race', 'sand', 'smoke', 'string', 'west', 'wheel', 'wine', 'arm', 'bet', 'blow', 'branch', 'breast', 'bunch', 'chip', 'coach', 'cross', 'draft', 'dust', 'floor', 'god', 'golf', 'judge', 'knife', 'league', 'mail', 'mess', 'pin', 'pool', 'pound', 'shame', 'shoe', 'tackle', 'tank', 'trust', 'bake', 'bar', 'bell', 'bike', 'blame', 'boy', 'brick', 'chair', 'clue', 'diet', 'fear', 'fuel', 'glove', 'lunch', 'nurse', 'pace', 'peak', 'plane', 'row', 'shock', 'spite', 'spray', 'till', 'yard', 'bend', 'bite', 'blind', 'bottle', 'cable', 'candle', 'clerk', 'cloud', 'harm', 'knee', 'load', 'neck', 'plate', 'purple', 'ruin', 'ship', 'skirt', 'slice', 'snow', 'stroke', 'switch', 'trash', 'tune', 'zone', 'bid', 'boot', 'bug', 'camp', 'cat', 'clock', 'cow', 'crack', 'fault', 'grass', 'guy', 'hell', 'joke', 'leg', 'lip', 'mate', 'nerve', 'pen', 'pride', 'priest', 'prize', 'ring', 'roof', 'rope', 'sail', 'scheme', 'script', 'sock', 'toe', 'truck', 'a', 'you', 'it', 'can', 'will', 'if', 'one', 'most', 'use', 'make', 'good', 'look', 'help', 'go', 'great', 'being', 'few', 'might', 'still', 'read', 'keep', 'start', 'give', 'she', 'long', 'play', 'feel', 'high', 'put', 'set', 'change', 'simple', 'past', 'big', 'cut', 'show', 'try', 'check', 'call', 'move', 'pay', 'let', 'single', 'turn', 'ask', 'buy', 'guard', 'hold', 'main', 'cook', 'whole', 'dance', 'cold', 'low', 'deal', 'worth', 'fall', 'search', 'spend', 'talk', 'tell', 'cost', 'drive', 'green', 'glad', 'run', 'due', 'middle', 'leave', 'reach', 'rest', 'serve', 'watch', 'charge', 'break', 'safe', 'stay', 'rise', 'walk', 'white', 'beyond', 'pick', 'lift', 'mix', 'stop', 'teach', 'fly', 'broad', 'gain', 'maybe', 'rich', 'save', 'stand', 'young', 'lead', 'handle', 'meet', 'sell', 'press', 'ride', 'spread', 'spring', 'tough', 'wait', 'brown', 'deep', 'flow', 'hit', 'shoot', 'touch', 'cry', 'dump', 'push', 'eat', 'fill', 'jump', 'kick', 'pass', 'pitch', 'treat', 'vast', 'beat', 'burn', 'print', 'raise', 'sleep', 'dark', 'double', 'draw', 'fix', 'hire', 'join', 'kill', 'tap', 'win', 'claim', 'drag', 'drink', 'guess', 'pull', 'raw', 'soft', 'wear', 'weird', 'count', 'dead', 'doubt', 'feed', 'round', 'sing', 'slide', 'strip', 'wish', 'dig', 'hang', 'hunt', 'march', 'tie', 'brief', 'hate', 'prior', 'rough', 'sad', 'scratch', 'sick', 'strike', 'hurt', 'laugh', 'lay', 'royal', 'split', 'strain', 'struggle', 'swim', 'train', 'wash', 'crash', 'fold', 'grab', 'hide', 'miss', 'quote', 'roll', 'sink', 'slip', 'spare', 'sweet', 'swing', 'twist', 'brave', 'calm', 'grand', 'male', 'mine', 'prompt', 'quiet', 'rush', 'shake', 'shift', 'shine', 'steal', 'suck', 'bear', 'dare', 'dear', 'drunk', 'kiss', 'neat', 'pop', 'punch', 'quit', 'rip', 'rub', 'smile', 'spell', 'stretch', 'tear', 'wake', 'wrap']\n",
      "s2 = ['system', 'music', 'person', 'reading', 'method', 'data', 'theory', 'problem', 'software', 'control', 'knowledge', 'power', 'nature', 'product', 'idea', 'area', 'story', 'media', 'oven', 'language', 'video', 'country', 'exam', 'physics', 'series', 'basis', 'boyfriend', 'army', 'freedom', 'paper', 'instance', 'writing', 'article', 'audience', 'fishing', 'income', 'marriage', 'user', 'failure', 'meaning', 'teacher', 'disease', 'nation', 'success', 'moment', 'painting', 'event', 'shopping', 'student', 'office', 'unit', 'context', 'driver', 'teaching', 'dealer', 'debate', 'finding', 'member', 'message', 'concept', 'housing', 'woman', 'advice', 'effort', 'payment', 'city', 'county', 'estate', 'photo', 'recipe', 'studio', 'topic', 'passion', 'resource', 'setting', 'college', 'patience', 'aspect', 'response', 'storage', 'version', 'complaint', 'contract', 'highway', 'union', 'cancer', 'entry', 'limit', 'mixture', 'region', 'virus', 'actor', 'classroom', 'device', 'drama', 'engine', 'football', 'guidance', 'hotel', 'owner', 'tension', 'climate', 'employer', 'respect', 'boring', 'cousin', 'extent', 'feedback', 'guitar', 'leader', 'outcome', 'revenue', 'session', 'singer', 'tennis', 'basket', 'bonus', 'childhood', 'clothes', 'dinner', 'drawing', 'hearing', 'judgment', 'orange', 'poetry', 'police', 'ratio', 'sector', 'vehicle', 'volume', 'airport', 'chapter', 'committee', 'error', 'farmer', 'presence', 'river', 'village', 'warning', 'winner', 'worker', 'writer', 'courage', 'drawer', 'garbage', 'honey', 'insect', 'ladder', 'menu', 'piano', 'reaction', 'salad', 'sister', 'weakness', 'wedding', 'affair', 'bathroom', 'bedroom', 'birthday', 'diamond', 'fortune', 'friendship', 'girlfriend', 'lady', 'midnight', 'pizza', 'platform', 'speaker', 'stranger', 'trainer', 'water', 'money', 'example', 'study', 'number', 'process', 'body', 'market', 'radio', 'training', 'amount', 'level', 'order', 'practice', 'research', 'service', 'answer', 'focus', 'matter', 'picture', 'access', 'garden', 'reason', 'future', 'demand', 'image', 'action', 'record', 'result', 'section', 'building', 'nothing', 'period', 'subject', 'weather', 'figure', 'model', 'program', 'chicken', 'design', 'feature', 'purpose', 'question', 'object', 'profit', 'inside', 'outside', 'standard', 'exchange', 'pressure', 'item', 'metal', 'review', 'structure', 'account', 'medium', 'balance', 'bottom', 'impact', 'machine', 'address', 'career', 'culture', 'morning', 'contact', 'credit', 'network', 'attempt', 'effect', 'challenge', 'exit', 'function', 'living', 'plastic', 'summer', 'button', 'desire', 'influence', 'notice', 'damage', 'distance', 'feeling', 'savings', 'sugar', 'target', 'author', 'budget', 'discount', 'lesson', 'minute', 'campaign', 'letter', 'novel', 'option', 'plenty', 'quarter', 'baby', 'background', 'carry', 'factor', 'master', 'traffic', 'appeal', 'ideal', 'kitchen', 'mother', 'party', 'principle', 'season', 'signal', 'spirit', 'copy', 'progress', 'project', 'status', 'ticket', 'breakfast', 'daughter', 'doctor', 'duty', 'essay', 'father', 'finance', 'substance', 'detail', 'mission', 'pleasure', 'shower', 'window', 'agent', 'contest', 'corner', 'district', 'finger', 'garage', 'guarantee', 'lecture', 'manner', 'meeting', 'parking', 'partner', 'profile', 'routine', 'schedule', 'swimming', 'winter', 'airline', 'bother', 'horror', 'husband', 'mistake', 'mountain', 'package', 'patient', 'relief', 'sentence', 'shoulder', 'stomach', 'tourist', 'towel', 'aside', 'border', 'brother', 'buddy', 'expert', 'habit', 'iron', 'landscape', 'native', 'parent', 'pattern', 'request', 'shelter', 'silver', 'assist', 'closet', 'collar', 'comment', 'devil', 'jacket', 'mortgage', 'panic', 'reward', 'sandwich', 'surprise', 'weekend', 'welcome', 'alarm', 'bicycle', 'concert', 'counter', 'flower', 'lawyer', 'leather', 'mirror', 'pension', 'anger', 'award', 'bitter', 'candy', 'carpet', 'champion', 'channel', 'comfort', 'entrance', 'highlight', 'island', 'jury', 'motor', 'passage', 'promise', 'resort', 'station', 'tower', 'witness', 'many', 'other', 'public', 'human', 'local', 'tonight', 'common', 'possible', 'today', 'major', 'current', 'second', 'increase', 'offer', 'travel', 'special', 'working', 'excuse', 'purchase', 'produce', 'present', 'creative', 'support', 'remove', 'return', 'complex', 'reserve', 'active', 'visit', 'visual', 'affect', 'cover', 'report', 'junior', 'unique', 'classic', 'final', 'private', 'western', 'concern', 'heavy', 'hello', 'listen', 'valuable', 'worry', 'leading', 'release', 'finish', 'normal', 'secret', 'display', 'cancel', 'extreme', 'conflict', 'formal', 'remote', 'total', 'abuse', 'advance', 'consist', 'equal', 'attack', 'constant', 'minor', 'solid', 'wonder', 'annual', 'impress', 'repeat', 'whereas', 'combine', 'command', 'divide', 'mention', 'survey', 'adult', 'crazy', 'escape', 'gather', 'repair', 'employ', 'mobile', 'nasty', 'respond', 'senior', 'upper', 'yellow', 'convert', 'funny', 'permit', 'resolve', 'suspect', 'upstairs', 'usual', 'abroad', 'refuse', 'regret', 'reveal', 'surround', 'brilliant', 'delay', 'female', 'hurry', 'invite', 'reply', 'resist', 'silly', 'stupid']\n",
      "s3 = ['history', 'family', 'government', 'computer', 'internet', 'library', 'investment', 'society', 'industry', 'safety', 'quality', 'variety', 'equipment', 'policy', 'direction', 'strategy', 'camera', 'marketing', 'department', 'difference', 'medicine', 'chemistry', 'energy', 'location', 'addition', 'apartment', 'politics', 'attention', 'decision', 'property', 'president', 'cigarette', 'performance', 'magazine', 'newspaper', 'appearance', 'customer', 'discussion', 'inflation', 'insurance', 'expression', 'importance', 'opinion', 'reality', 'situation', 'statement', 'foundation', 'grandmother', 'perspective', 'collection', 'depression', 'percentage', 'agency', 'connection', 'criticism', 'description', 'memory', 'solution', 'attitude', 'director', 'selection', 'alcohol', 'argument', 'emphasis', 'membership', 'possession', 'agreement', 'currency', 'employment', 'preference', 'republic', 'tradition', 'election', 'priority', 'protection', 'suggestion', 'variation', 'anxiety', 'atmosphere', 'confusion', 'construction', 'emotion', 'leadership', 'manager', 'recording', 'charity', 'disaster', 'editor', 'homework', 'permission', 'promotion', 'reflection', 'cabinet', 'procedure', 'relation', 'restaurant', 'signature', 'accident', 'appointment', 'arrival', 'assumption', 'baseball', 'database', 'enthusiasm', 'historian', 'hospital', 'injury', 'instruction', 'maintenance', 'perception', 'proposal', 'reception', 'assistance', 'chocolate', 'conclusion', 'grocery', 'impression', 'inspection', 'inspector', 'penalty', 'potato', 'profession', 'professor', 'quantity', 'ambition', 'analyst', 'assignment', 'assistant', 'championship', 'consequence', 'departure', 'funeral', 'intention', 'passenger', 'pollution', 'surgery', 'sympathy', 'business', 'experience', 'interest', 'company', 'exercise', 'beginning', 'material', 'position', 'advantage', 'benefit', 'discipline', 'average', 'condition', 'capital', 'animal', 'officer', 'reference', 'register', 'character', 'evidence', 'maximum', 'vegetable', 'relative', 'commission', 'minimum', 'confidence', 'afternoon', 'interview', 'calendar', 'candidate', 'implement', 'telephone', 'designer', 'dimension', 'evening', 'extension', 'holiday', 'occasion', 'vacation', 'associate', 'document', 'opening', 'salary', 'conference', 'monitor', 'transition', 'grandfather', 'specialist', 'engineer', 'incident', 'resident', 'general', 'specific', 'personal', 'national', 'natural', 'physical', 'potential', 'following', 'commercial', 'primary', 'positive', 'effective', 'regular', 'beautiful', 'negative', 'anything', 'familiar', 'official', 'comfortable', 'objective', 'chemical', 'opposite', 'deposit', 'somewhere', 'anywhere', 'internal', 'sensitive', 'forever', 'nobody', 'initial', 'spiritual', 'external', 'illegal', 'dependent', 'recover', 'concentrate', 'estimate', 'tomorrow', 'yesterday']\n",
      "s4 = ['information', 'understanding', 'literature', 'ability', 'economics', 'television', 'temperature', 'activity', 'community', 'definition', 'development', 'management', 'security', 'analysis', 'technology', 'environment', 'combination', 'philosophy', 'advertising', 'education', 'competition', 'distribution', 'entertainment', 'population', 'category', 'introduction', 'relationship', 'association', 'application', 'secretary', 'psychology', 'preparation', 'engineering', 'interaction', 'delivery', 'difficulty', 'awareness', 'comparison', 'elevator', 'operation', 'transportation', 'efficiency', 'excitement', 'presentation', 'resolution', 'initiative', 'measurement', 'satisfaction', 'significance', 'conversation', 'explanation', 'replacement', 'revolution', 'contribution', 'establishment', 'improvement', 'independence', 'requirement', 'supermarket', 'celebration', 'indication', 'negotiation', 'obligation', 'recognition', 'reputation', 'economy', 'emergency', 'particular', 'individual', 'professional', 'alternative', 'necessary', 'independent', 'original', 'equivalent', 'ordinary', 'anybody', 'inevitable', 'temporary']\n",
      "s5 = ['organization', 'university', 'communication', 'opportunity', 'imagination', 'administration', 'personality', 'recommendation', 'refrigerator', 'possibility', 'manufacturer', 'examination', 'consideration', 'international', 'representative']\n",
      "s6 = ['responsibility']\n"
     ]
    }
   ],
   "source": [
    "# 將詞語依據音節數分類，產生s1 s2 s3 s4 s5 s6\n",
    "nouns = [\n",
    "    'people',\n",
    "    'history',\n",
    "    'way',\n",
    "    'art',\n",
    "    'world',\n",
    "    'information',\n",
    "    'map',\n",
    "    'two',\n",
    "    'family',\n",
    "    'government',\n",
    "    'health',\n",
    "    'system',\n",
    "    'computer',\n",
    "    'meat',\n",
    "    'year',\n",
    "    'thanks',\n",
    "    'music',\n",
    "    'person',\n",
    "    'reading',\n",
    "    'method',\n",
    "    'data',\n",
    "    'food',\n",
    "    'understanding',\n",
    "    'theory',\n",
    "    'law',\n",
    "    'bird',\n",
    "    'literature',\n",
    "    'problem',\n",
    "    'software',\n",
    "    'control',\n",
    "    'knowledge',\n",
    "    'power',\n",
    "    'ability',\n",
    "    'economics',\n",
    "    'love',\n",
    "    'internet',\n",
    "    'television',\n",
    "    'science',\n",
    "    'library',\n",
    "    'nature',\n",
    "    'fact',\n",
    "    'product',\n",
    "    'idea',\n",
    "    'temperature',\n",
    "    'investment',\n",
    "    'area',\n",
    "    'society',\n",
    "    'activity',\n",
    "    'story',\n",
    "    'industry',\n",
    "    'media',\n",
    "    'thing',\n",
    "    'oven',\n",
    "    'community',\n",
    "    'definition',\n",
    "    'safety',\n",
    "    'quality',\n",
    "    'development',\n",
    "    'language',\n",
    "    'management',\n",
    "    'player',\n",
    "    'variety',\n",
    "    'video',\n",
    "    'week',\n",
    "    'security',\n",
    "    'country',\n",
    "    'exam',\n",
    "    'movie',\n",
    "    'organization',\n",
    "    'equipment',\n",
    "    'physics',\n",
    "    'analysis',\n",
    "    'policy',\n",
    "    'series',\n",
    "    'thought',\n",
    "    'basis',\n",
    "    'boyfriend',\n",
    "    'direction',\n",
    "    'strategy',\n",
    "    'technology',\n",
    "    'army',\n",
    "    'camera',\n",
    "    'freedom',\n",
    "    'paper',\n",
    "    'environment',\n",
    "    'child',\n",
    "    'instance',\n",
    "    'month',\n",
    "    'truth',\n",
    "    'marketing',\n",
    "    'university',\n",
    "    'writing',\n",
    "    'article',\n",
    "    'department',\n",
    "    'difference',\n",
    "    'goal',\n",
    "    'news',\n",
    "    'audience',\n",
    "    'fishing',\n",
    "    'growth',\n",
    "    'income',\n",
    "    'marriage',\n",
    "    'user',\n",
    "    'combination',\n",
    "    'failure',\n",
    "    'meaning',\n",
    "    'medicine',\n",
    "    'philosophy',\n",
    "    'teacher',\n",
    "    'communication',\n",
    "    'night',\n",
    "    'chemistry',\n",
    "    'disease',\n",
    "    'disk',\n",
    "    'energy',\n",
    "    'nation',\n",
    "    'road',\n",
    "    'role',\n",
    "    'soup',\n",
    "    'advertising',\n",
    "    'location',\n",
    "    'success',\n",
    "    'addition',\n",
    "    'apartment',\n",
    "    'education',\n",
    "    'math',\n",
    "    'moment',\n",
    "    'painting',\n",
    "    'politics',\n",
    "    'attention',\n",
    "    'decision',\n",
    "    'event',\n",
    "    'property',\n",
    "    'shopping',\n",
    "    'student',\n",
    "    'wood',\n",
    "    'competition',\n",
    "    'distribution',\n",
    "    'entertainment',\n",
    "    'office',\n",
    "    'population',\n",
    "    'president',\n",
    "    'unit',\n",
    "    'category',\n",
    "    'cigarette',\n",
    "    'context',\n",
    "    'introduction',\n",
    "    'opportunity',\n",
    "    'performance',\n",
    "    'driver',\n",
    "    'flight',\n",
    "    'length',\n",
    "    'magazine',\n",
    "    'newspaper',\n",
    "    'relationship',\n",
    "    'teaching',\n",
    "    'cell',\n",
    "    'dealer',\n",
    "    'debate',\n",
    "    'finding',\n",
    "    'lake',\n",
    "    'member',\n",
    "    'message',\n",
    "    'phone',\n",
    "    'scene',\n",
    "    'appearance',\n",
    "    'association',\n",
    "    'concept',\n",
    "    'customer',\n",
    "    'death',\n",
    "    'discussion',\n",
    "    'housing',\n",
    "    'inflation',\n",
    "    'insurance',\n",
    "    'mood',\n",
    "    'woman',\n",
    "    'advice',\n",
    "    'blood',\n",
    "    'effort',\n",
    "    'expression',\n",
    "    'importance',\n",
    "    'opinion',\n",
    "    'payment',\n",
    "    'reality',\n",
    "    'responsibility',\n",
    "    'situation',\n",
    "    'skill',\n",
    "    'statement',\n",
    "    'wealth',\n",
    "    'application',\n",
    "    'city',\n",
    "    'county',\n",
    "    'depth',\n",
    "    'estate',\n",
    "    'foundation',\n",
    "    'grandmother',\n",
    "    'heart',\n",
    "    'perspective',\n",
    "    'photo',\n",
    "    'recipe',\n",
    "    'studio',\n",
    "    'topic',\n",
    "    'collection',\n",
    "    'depression',\n",
    "    'imagination',\n",
    "    'passion',\n",
    "    'percentage',\n",
    "    'resource',\n",
    "    'setting',\n",
    "    'ad',\n",
    "    'agency',\n",
    "    'college',\n",
    "    'connection',\n",
    "    'criticism',\n",
    "    'debt',\n",
    "    'description',\n",
    "    'memory',\n",
    "    'patience',\n",
    "    'secretary',\n",
    "    'solution',\n",
    "    'administration',\n",
    "    'aspect',\n",
    "    'attitude',\n",
    "    'director',\n",
    "    'personality',\n",
    "    'psychology',\n",
    "    'recommendation',\n",
    "    'response',\n",
    "    'selection',\n",
    "    'storage',\n",
    "    'version',\n",
    "    'alcohol',\n",
    "    'argument',\n",
    "    'complaint',\n",
    "    'contract',\n",
    "    'emphasis',\n",
    "    'highway',\n",
    "    'loss',\n",
    "    'membership',\n",
    "    'possession',\n",
    "    'preparation',\n",
    "    'steak',\n",
    "    'union',\n",
    "    'agreement',\n",
    "    'cancer',\n",
    "    'currency',\n",
    "    'employment',\n",
    "    'engineering',\n",
    "    'entry',\n",
    "    'interaction',\n",
    "    'limit',\n",
    "    'mixture',\n",
    "    'preference',\n",
    "    'region',\n",
    "    'republic',\n",
    "    'seat',\n",
    "    'tradition',\n",
    "    'virus',\n",
    "    'actor',\n",
    "    'classroom',\n",
    "    'delivery',\n",
    "    'device',\n",
    "    'difficulty',\n",
    "    'drama',\n",
    "    'election',\n",
    "    'engine',\n",
    "    'football',\n",
    "    'guidance',\n",
    "    'hotel',\n",
    "    'match',\n",
    "    'owner',\n",
    "    'priority',\n",
    "    'protection',\n",
    "    'suggestion',\n",
    "    'tension',\n",
    "    'variation',\n",
    "    'anxiety',\n",
    "    'atmosphere',\n",
    "    'awareness',\n",
    "    'bread',\n",
    "    'climate',\n",
    "    'comparison',\n",
    "    'confusion',\n",
    "    'construction',\n",
    "    'elevator',\n",
    "    'emotion',\n",
    "    'employee',\n",
    "    'employer',\n",
    "    'guest',\n",
    "    'height',\n",
    "    'leadership',\n",
    "    'mall',\n",
    "    'manager',\n",
    "    'operation',\n",
    "    'recording',\n",
    "    'respect',\n",
    "    'sample',\n",
    "    'transportation',\n",
    "    'boring',\n",
    "    'charity',\n",
    "    'cousin',\n",
    "    'disaster',\n",
    "    'editor',\n",
    "    'efficiency',\n",
    "    'excitement',\n",
    "    'extent',\n",
    "    'feedback',\n",
    "    'guitar',\n",
    "    'homework',\n",
    "    'leader',\n",
    "    'mom',\n",
    "    'outcome',\n",
    "    'permission',\n",
    "    'presentation',\n",
    "    'promotion',\n",
    "    'reflection',\n",
    "    'refrigerator',\n",
    "    'resolution',\n",
    "    'revenue',\n",
    "    'session',\n",
    "    'singer',\n",
    "    'tennis',\n",
    "    'basket',\n",
    "    'bonus',\n",
    "    'cabinet',\n",
    "    'childhood',\n",
    "    'church',\n",
    "    'clothes',\n",
    "    'coffee',\n",
    "    'dinner',\n",
    "    'drawing',\n",
    "    'hair',\n",
    "    'hearing',\n",
    "    'initiative',\n",
    "    'judgment',\n",
    "    'lab',\n",
    "    'measurement',\n",
    "    'mode',\n",
    "    'mud',\n",
    "    'orange',\n",
    "    'poetry',\n",
    "    'police',\n",
    "    'possibility',\n",
    "    'procedure',\n",
    "    'queen',\n",
    "    'ratio',\n",
    "    'relation',\n",
    "    'restaurant',\n",
    "    'satisfaction',\n",
    "    'sector',\n",
    "    'signature',\n",
    "    'significance',\n",
    "    'song',\n",
    "    'tooth',\n",
    "    'town',\n",
    "    'vehicle',\n",
    "    'volume',\n",
    "    'wife',\n",
    "    'accident',\n",
    "    'airport',\n",
    "    'appointment',\n",
    "    'arrival',\n",
    "    'assumption',\n",
    "    'baseball',\n",
    "    'chapter',\n",
    "    'committee',\n",
    "    'conversation',\n",
    "    'database',\n",
    "    'enthusiasm',\n",
    "    'error',\n",
    "    'explanation',\n",
    "    'farmer',\n",
    "    'gate',\n",
    "    'girl',\n",
    "    'hall',\n",
    "    'historian',\n",
    "    'hospital',\n",
    "    'injury',\n",
    "    'instruction',\n",
    "    'maintenance',\n",
    "    'manufacturer',\n",
    "    'meal',\n",
    "    'perception',\n",
    "    'pie',\n",
    "    'poem',\n",
    "    'presence',\n",
    "    'proposal',\n",
    "    'reception',\n",
    "    'replacement',\n",
    "    'revolution',\n",
    "    'river',\n",
    "    'son',\n",
    "    'speech',\n",
    "    'tea',\n",
    "    'village',\n",
    "    'warning',\n",
    "    'winner',\n",
    "    'worker',\n",
    "    'writer',\n",
    "    'assistance',\n",
    "    'breath',\n",
    "    'buyer',\n",
    "    'chest',\n",
    "    'chocolate',\n",
    "    'conclusion',\n",
    "    'contribution',\n",
    "    'cookie',\n",
    "    'courage',\n",
    "    'dad',\n",
    "    'desk',\n",
    "    'drawer',\n",
    "    'establishment',\n",
    "    'examination',\n",
    "    'garbage',\n",
    "    'grocery',\n",
    "    'honey',\n",
    "    'impression',\n",
    "    'improvement',\n",
    "    'independence',\n",
    "    'insect',\n",
    "    'inspection',\n",
    "    'inspector',\n",
    "    'king',\n",
    "    'ladder',\n",
    "    'menu',\n",
    "    'penalty',\n",
    "    'piano',\n",
    "    'potato',\n",
    "    'profession',\n",
    "    'professor',\n",
    "    'quantity',\n",
    "    'reaction',\n",
    "    'requirement',\n",
    "    'salad',\n",
    "    'sister',\n",
    "    'supermarket',\n",
    "    'tongue',\n",
    "    'weakness',\n",
    "    'wedding',\n",
    "    'affair',\n",
    "    'ambition',\n",
    "    'analyst',\n",
    "    'apple',\n",
    "    'assignment',\n",
    "    'assistant',\n",
    "    'bathroom',\n",
    "    'bedroom',\n",
    "    'beer',\n",
    "    'birthday',\n",
    "    'celebration',\n",
    "    'championship',\n",
    "    'cheek',\n",
    "    'client',\n",
    "    'consequence',\n",
    "    'departure',\n",
    "    'diamond',\n",
    "    'dirt',\n",
    "    'ear',\n",
    "    'fortune',\n",
    "    'friendship',\n",
    "    'funeral',\n",
    "    'gene',\n",
    "    'girlfriend',\n",
    "    'hat',\n",
    "    'indication',\n",
    "    'intention',\n",
    "    'lady',\n",
    "    'midnight',\n",
    "    'negotiation',\n",
    "    'obligation',\n",
    "    'passenger',\n",
    "    'pizza',\n",
    "    'platform',\n",
    "    'poet',\n",
    "    'pollution',\n",
    "    'recognition',\n",
    "    'reputation',\n",
    "    'shirt',\n",
    "    'sir',\n",
    "    'speaker',\n",
    "    'stranger',\n",
    "    'surgery',\n",
    "    'sympathy',\n",
    "    'tale',\n",
    "    'throat',\n",
    "    'trainer',\n",
    "    'uncle',\n",
    "    'youth',\n",
    "    'time',\n",
    "    'work',\n",
    "    'film',\n",
    "    'water',\n",
    "    'money',\n",
    "    'example',\n",
    "    'while',\n",
    "    'business',\n",
    "    'study',\n",
    "    'game',\n",
    "    'life',\n",
    "    'form',\n",
    "    'air',\n",
    "    'day',\n",
    "    'place',\n",
    "    'number',\n",
    "    'part',\n",
    "    'field',\n",
    "    'fish',\n",
    "    'back',\n",
    "    'process',\n",
    "    'heat',\n",
    "    'hand',\n",
    "    'experience',\n",
    "    'job',\n",
    "    'book',\n",
    "    'end',\n",
    "    'point',\n",
    "    'type',\n",
    "    'home',\n",
    "    'economy',\n",
    "    'value',\n",
    "    'body',\n",
    "    'market',\n",
    "    'guide',\n",
    "    'interest',\n",
    "    'state',\n",
    "    'radio',\n",
    "    'course',\n",
    "    'company',\n",
    "    'price',\n",
    "    'size',\n",
    "    'card',\n",
    "    'list',\n",
    "    'mind',\n",
    "    'trade',\n",
    "    'line',\n",
    "    'care',\n",
    "    'group',\n",
    "    'risk',\n",
    "    'word',\n",
    "    'fat',\n",
    "    'force',\n",
    "    'key',\n",
    "    'light',\n",
    "    'training',\n",
    "    'name',\n",
    "    'school',\n",
    "    'top',\n",
    "    'amount',\n",
    "    'level',\n",
    "    'order',\n",
    "    'practice',\n",
    "    'research',\n",
    "    'sense',\n",
    "    'service',\n",
    "    'piece',\n",
    "    'web',\n",
    "    'boss',\n",
    "    'sport',\n",
    "    'fun',\n",
    "    'house',\n",
    "    'page',\n",
    "    'term',\n",
    "    'test',\n",
    "    'answer',\n",
    "    'sound',\n",
    "    'focus',\n",
    "    'matter',\n",
    "    'kind',\n",
    "    'soil',\n",
    "    'board',\n",
    "    'oil',\n",
    "    'picture',\n",
    "    'access',\n",
    "    'garden',\n",
    "    'range',\n",
    "    'rate',\n",
    "    'reason',\n",
    "    'future',\n",
    "    'site',\n",
    "    'demand',\n",
    "    'exercise',\n",
    "    'image',\n",
    "    'case',\n",
    "    'cause',\n",
    "    'coast',\n",
    "    'action',\n",
    "    'age',\n",
    "    'bad',\n",
    "    'boat',\n",
    "    'record',\n",
    "    'result',\n",
    "    'section',\n",
    "    'building',\n",
    "    'mouse',\n",
    "    'cash',\n",
    "    'class',\n",
    "    'nothing',\n",
    "    'period',\n",
    "    'plan',\n",
    "    'store',\n",
    "    'tax',\n",
    "    'side',\n",
    "    'subject',\n",
    "    'space',\n",
    "    'rule',\n",
    "    'stock',\n",
    "    'weather',\n",
    "    'chance',\n",
    "    'figure',\n",
    "    'man',\n",
    "    'model',\n",
    "    'source',\n",
    "    'beginning',\n",
    "    'earth',\n",
    "    'program',\n",
    "    'chicken',\n",
    "    'design',\n",
    "    'feature',\n",
    "    'head',\n",
    "    'material',\n",
    "    'purpose',\n",
    "    'question',\n",
    "    'rock',\n",
    "    'salt',\n",
    "    'act',\n",
    "    'birth',\n",
    "    'car',\n",
    "    'dog',\n",
    "    'object',\n",
    "    'scale',\n",
    "    'sun',\n",
    "    'note',\n",
    "    'profit',\n",
    "    'rent',\n",
    "    'speed',\n",
    "    'style',\n",
    "    'war',\n",
    "    'bank',\n",
    "    'craft',\n",
    "    'half',\n",
    "    'inside',\n",
    "    'outside',\n",
    "    'standard',\n",
    "    'bus',\n",
    "    'exchange',\n",
    "    'eye',\n",
    "    'fire',\n",
    "    'position',\n",
    "    'pressure',\n",
    "    'stress',\n",
    "    'advantage',\n",
    "    'benefit',\n",
    "    'box',\n",
    "    'frame',\n",
    "    'issue',\n",
    "    'step',\n",
    "    'cycle',\n",
    "    'face',\n",
    "    'item',\n",
    "    'metal',\n",
    "    'paint',\n",
    "    'review',\n",
    "    'room',\n",
    "    'screen',\n",
    "    'structure',\n",
    "    'view',\n",
    "    'account',\n",
    "    'ball',\n",
    "    'discipline',\n",
    "    'medium',\n",
    "    'share',\n",
    "    'balance',\n",
    "    'bit',\n",
    "    'black',\n",
    "    'bottom',\n",
    "    'choice',\n",
    "    'gift',\n",
    "    'impact',\n",
    "    'machine',\n",
    "    'shape',\n",
    "    'tool',\n",
    "    'wind',\n",
    "    'address',\n",
    "    'average',\n",
    "    'career',\n",
    "    'culture',\n",
    "    'morning',\n",
    "    'pot',\n",
    "    'sign',\n",
    "    'table',\n",
    "    'task',\n",
    "    'condition',\n",
    "    'contact',\n",
    "    'credit',\n",
    "    'egg',\n",
    "    'hope',\n",
    "    'ice',\n",
    "    'network',\n",
    "    'north',\n",
    "    'square',\n",
    "    'attempt',\n",
    "    'date',\n",
    "    'effect',\n",
    "    'link',\n",
    "    'post',\n",
    "    'star',\n",
    "    'voice',\n",
    "    'capital',\n",
    "    'challenge',\n",
    "    'friend',\n",
    "    'self',\n",
    "    'shot',\n",
    "    'brush',\n",
    "    'couple',\n",
    "    'exit',\n",
    "    'front',\n",
    "    'function',\n",
    "    'lack',\n",
    "    'living',\n",
    "    'plant',\n",
    "    'plastic',\n",
    "    'spot',\n",
    "    'summer',\n",
    "    'taste',\n",
    "    'theme',\n",
    "    'track',\n",
    "    'wing',\n",
    "    'brain',\n",
    "    'button',\n",
    "    'click',\n",
    "    'desire',\n",
    "    'foot',\n",
    "    'gas',\n",
    "    'influence',\n",
    "    'notice',\n",
    "    'rain',\n",
    "    'wall',\n",
    "    'base',\n",
    "    'damage',\n",
    "    'distance',\n",
    "    'feeling',\n",
    "    'pair',\n",
    "    'savings',\n",
    "    'staff',\n",
    "    'sugar',\n",
    "    'target',\n",
    "    'text',\n",
    "    'animal',\n",
    "    'author',\n",
    "    'budget',\n",
    "    'discount',\n",
    "    'file',\n",
    "    'ground',\n",
    "    'lesson',\n",
    "    'minute',\n",
    "    'officer',\n",
    "    'phase',\n",
    "    'reference',\n",
    "    'register',\n",
    "    'sky',\n",
    "    'stage',\n",
    "    'stick',\n",
    "    'title',\n",
    "    'trouble',\n",
    "    'bowl',\n",
    "    'bridge',\n",
    "    'campaign',\n",
    "    'character',\n",
    "    'club',\n",
    "    'edge',\n",
    "    'evidence',\n",
    "    'fan',\n",
    "    'letter',\n",
    "    'lock',\n",
    "    'maximum',\n",
    "    'novel',\n",
    "    'option',\n",
    "    'pack',\n",
    "    'park',\n",
    "    'plenty',\n",
    "    'quarter',\n",
    "    'skin',\n",
    "    'sort',\n",
    "    'weight',\n",
    "    'baby',\n",
    "    'background',\n",
    "    'carry',\n",
    "    'dish',\n",
    "    'factor',\n",
    "    'fruit',\n",
    "    'glass',\n",
    "    'joint',\n",
    "    'master',\n",
    "    'muscle',\n",
    "    'red',\n",
    "    'strength',\n",
    "    'traffic',\n",
    "    'trip',\n",
    "    'vegetable',\n",
    "    'appeal',\n",
    "    'chart',\n",
    "    'gear',\n",
    "    'ideal',\n",
    "    'kitchen',\n",
    "    'land',\n",
    "    'log',\n",
    "    'mother',\n",
    "    'net',\n",
    "    'party',\n",
    "    'principle',\n",
    "    'relative',\n",
    "    'sale',\n",
    "    'season',\n",
    "    'signal',\n",
    "    'spirit',\n",
    "    'street',\n",
    "    'tree',\n",
    "    'wave',\n",
    "    'belt',\n",
    "    'bench',\n",
    "    'commission',\n",
    "    'copy',\n",
    "    'drop',\n",
    "    'minimum',\n",
    "    'path',\n",
    "    'progress',\n",
    "    'project',\n",
    "    'sea',\n",
    "    'south',\n",
    "    'status',\n",
    "    'stuff',\n",
    "    'ticket',\n",
    "    'tour',\n",
    "    'angle',\n",
    "    'blue',\n",
    "    'breakfast',\n",
    "    'confidence',\n",
    "    'daughter',\n",
    "    'degree',\n",
    "    'doctor',\n",
    "    'dot',\n",
    "    'dream',\n",
    "    'duty',\n",
    "    'essay',\n",
    "    'father',\n",
    "    'fee',\n",
    "    'finance',\n",
    "    'hour',\n",
    "    'juice',\n",
    "    'luck',\n",
    "    'milk',\n",
    "    'mouth',\n",
    "    'peace',\n",
    "    'pipe',\n",
    "    'stable',\n",
    "    'storm',\n",
    "    'substance',\n",
    "    'team',\n",
    "    'trick',\n",
    "    'afternoon',\n",
    "    'bat',\n",
    "    'beach',\n",
    "    'blank',\n",
    "    'catch',\n",
    "    'chain',\n",
    "    'consideration',\n",
    "    'cream',\n",
    "    'crew',\n",
    "    'detail',\n",
    "    'gold',\n",
    "    'interview',\n",
    "    'kid',\n",
    "    'mark',\n",
    "    'mission',\n",
    "    'pain',\n",
    "    'pleasure',\n",
    "    'score',\n",
    "    'screw',\n",
    "    'sex',\n",
    "    'shop',\n",
    "    'shower',\n",
    "    'suit',\n",
    "    'tone',\n",
    "    'window',\n",
    "    'agent',\n",
    "    'band',\n",
    "    'bath',\n",
    "    'block',\n",
    "    'bone',\n",
    "    'calendar',\n",
    "    'candidate',\n",
    "    'cap',\n",
    "    'coat',\n",
    "    'contest',\n",
    "    'corner',\n",
    "    'court',\n",
    "    'cup',\n",
    "    'district',\n",
    "    'door',\n",
    "    'east',\n",
    "    'finger',\n",
    "    'garage',\n",
    "    'guarantee',\n",
    "    'hole',\n",
    "    'hook',\n",
    "    'implement',\n",
    "    'layer',\n",
    "    'lecture',\n",
    "    'lie',\n",
    "    'manner',\n",
    "    'meeting',\n",
    "    'nose',\n",
    "    'parking',\n",
    "    'partner',\n",
    "    'profile',\n",
    "    'rice',\n",
    "    'routine',\n",
    "    'schedule',\n",
    "    'swimming',\n",
    "    'telephone',\n",
    "    'tip',\n",
    "    'winter',\n",
    "    'airline',\n",
    "    'bag',\n",
    "    'battle',\n",
    "    'bed',\n",
    "    'bill',\n",
    "    'bother',\n",
    "    'cake',\n",
    "    'code',\n",
    "    'curve',\n",
    "    'designer',\n",
    "    'dimension',\n",
    "    'dress',\n",
    "    'ease',\n",
    "    'emergency',\n",
    "    'evening',\n",
    "    'extension',\n",
    "    'farm',\n",
    "    'fight',\n",
    "    'gap',\n",
    "    'grade',\n",
    "    'holiday',\n",
    "    'horror',\n",
    "    'horse',\n",
    "    'host',\n",
    "    'husband',\n",
    "    'loan',\n",
    "    'mistake',\n",
    "    'mountain',\n",
    "    'nail',\n",
    "    'noise',\n",
    "    'occasion',\n",
    "    'package',\n",
    "    'patient',\n",
    "    'pause',\n",
    "    'phrase',\n",
    "    'proof',\n",
    "    'race',\n",
    "    'relief',\n",
    "    'sand',\n",
    "    'sentence',\n",
    "    'shoulder',\n",
    "    'smoke',\n",
    "    'stomach',\n",
    "    'string',\n",
    "    'tourist',\n",
    "    'towel',\n",
    "    'vacation',\n",
    "    'west',\n",
    "    'wheel',\n",
    "    'wine',\n",
    "    'arm',\n",
    "    'aside',\n",
    "    'associate',\n",
    "    'bet',\n",
    "    'blow',\n",
    "    'border',\n",
    "    'branch',\n",
    "    'breast',\n",
    "    'brother',\n",
    "    'buddy',\n",
    "    'bunch',\n",
    "    'chip',\n",
    "    'coach',\n",
    "    'cross',\n",
    "    'document',\n",
    "    'draft',\n",
    "    'dust',\n",
    "    'expert',\n",
    "    'floor',\n",
    "    'god',\n",
    "    'golf',\n",
    "    'habit',\n",
    "    'iron',\n",
    "    'judge',\n",
    "    'knife',\n",
    "    'landscape',\n",
    "    'league',\n",
    "    'mail',\n",
    "    'mess',\n",
    "    'native',\n",
    "    'opening',\n",
    "    'parent',\n",
    "    'pattern',\n",
    "    'pin',\n",
    "    'pool',\n",
    "    'pound',\n",
    "    'request',\n",
    "    'salary',\n",
    "    'shame',\n",
    "    'shelter',\n",
    "    'shoe',\n",
    "    'silver',\n",
    "    'tackle',\n",
    "    'tank',\n",
    "    'trust',\n",
    "    'assist',\n",
    "    'bake',\n",
    "    'bar',\n",
    "    'bell',\n",
    "    'bike',\n",
    "    'blame',\n",
    "    'boy',\n",
    "    'brick',\n",
    "    'chair',\n",
    "    'closet',\n",
    "    'clue',\n",
    "    'collar',\n",
    "    'comment',\n",
    "    'conference',\n",
    "    'devil',\n",
    "    'diet',\n",
    "    'fear',\n",
    "    'fuel',\n",
    "    'glove',\n",
    "    'jacket',\n",
    "    'lunch',\n",
    "    'monitor',\n",
    "    'mortgage',\n",
    "    'nurse',\n",
    "    'pace',\n",
    "    'panic',\n",
    "    'peak',\n",
    "    'plane',\n",
    "    'reward',\n",
    "    'row',\n",
    "    'sandwich',\n",
    "    'shock',\n",
    "    'spite',\n",
    "    'spray',\n",
    "    'surprise',\n",
    "    'till',\n",
    "    'transition',\n",
    "    'weekend',\n",
    "    'welcome',\n",
    "    'yard',\n",
    "    'alarm',\n",
    "    'bend',\n",
    "    'bicycle',\n",
    "    'bite',\n",
    "    'blind',\n",
    "    'bottle',\n",
    "    'cable',\n",
    "    'candle',\n",
    "    'clerk',\n",
    "    'cloud',\n",
    "    'concert',\n",
    "    'counter',\n",
    "    'flower',\n",
    "    'grandfather',\n",
    "    'harm',\n",
    "    'knee',\n",
    "    'lawyer',\n",
    "    'leather',\n",
    "    'load',\n",
    "    'mirror',\n",
    "    'neck',\n",
    "    'pension',\n",
    "    'plate',\n",
    "    'purple',\n",
    "    'ruin',\n",
    "    'ship',\n",
    "    'skirt',\n",
    "    'slice',\n",
    "    'snow',\n",
    "    'specialist',\n",
    "    'stroke',\n",
    "    'switch',\n",
    "    'trash',\n",
    "    'tune',\n",
    "    'zone',\n",
    "    'anger',\n",
    "    'award',\n",
    "    'bid',\n",
    "    'bitter',\n",
    "    'boot',\n",
    "    'bug',\n",
    "    'camp',\n",
    "    'candy',\n",
    "    'carpet',\n",
    "    'cat',\n",
    "    'champion',\n",
    "    'channel',\n",
    "    'clock',\n",
    "    'comfort',\n",
    "    'cow',\n",
    "    'crack',\n",
    "    'engineer',\n",
    "    'entrance',\n",
    "    'fault',\n",
    "    'grass',\n",
    "    'guy',\n",
    "    'hell',\n",
    "    'highlight',\n",
    "    'incident',\n",
    "    'island',\n",
    "    'joke',\n",
    "    'jury',\n",
    "    'leg',\n",
    "    'lip',\n",
    "    'mate',\n",
    "    'motor',\n",
    "    'nerve',\n",
    "    'passage',\n",
    "    'pen',\n",
    "    'pride',\n",
    "    'priest',\n",
    "    'prize',\n",
    "    'promise',\n",
    "    'resident',\n",
    "    'resort',\n",
    "    'ring',\n",
    "    'roof',\n",
    "    'rope',\n",
    "    'sail',\n",
    "    'scheme',\n",
    "    'script',\n",
    "    'sock',\n",
    "    'station',\n",
    "    'toe',\n",
    "    'tower',\n",
    "    'truck',\n",
    "    'witness',\n",
    "    'a',\n",
    "    'you',\n",
    "    'it',\n",
    "    'can',\n",
    "    'will',\n",
    "    'if',\n",
    "    'one',\n",
    "    'many',\n",
    "    'most',\n",
    "    'other',\n",
    "    'use',\n",
    "    'make',\n",
    "    'good',\n",
    "    'look',\n",
    "    'help',\n",
    "    'go',\n",
    "    'great',\n",
    "    'being',\n",
    "    'few',\n",
    "    'might',\n",
    "    'still',\n",
    "    'public',\n",
    "    'read',\n",
    "    'keep',\n",
    "    'start',\n",
    "    'give',\n",
    "    'human',\n",
    "    'local',\n",
    "    'general',\n",
    "    'she',\n",
    "    'specific',\n",
    "    'long',\n",
    "    'play',\n",
    "    'feel',\n",
    "    'high',\n",
    "    'tonight',\n",
    "    'put',\n",
    "    'common',\n",
    "    'set',\n",
    "    'change',\n",
    "    'simple',\n",
    "    'past',\n",
    "    'big',\n",
    "    'possible',\n",
    "    'particular',\n",
    "    'today',\n",
    "    'major',\n",
    "    'personal',\n",
    "    'current',\n",
    "    'national',\n",
    "    'cut',\n",
    "    'natural',\n",
    "    'physical',\n",
    "    'show',\n",
    "    'try',\n",
    "    'check',\n",
    "    'second',\n",
    "    'call',\n",
    "    'move',\n",
    "    'pay',\n",
    "    'let',\n",
    "    'increase',\n",
    "    'single',\n",
    "    'individual',\n",
    "    'turn',\n",
    "    'ask',\n",
    "    'buy',\n",
    "    'guard',\n",
    "    'hold',\n",
    "    'main',\n",
    "    'offer',\n",
    "    'potential',\n",
    "    'professional',\n",
    "    'international',\n",
    "    'travel',\n",
    "    'cook',\n",
    "    'alternative',\n",
    "    'following',\n",
    "    'special',\n",
    "    'working',\n",
    "    'whole',\n",
    "    'dance',\n",
    "    'excuse',\n",
    "    'cold',\n",
    "    'commercial',\n",
    "    'low',\n",
    "    'purchase',\n",
    "    'deal',\n",
    "    'primary',\n",
    "    'worth',\n",
    "    'fall',\n",
    "    'necessary',\n",
    "    'positive',\n",
    "    'produce',\n",
    "    'search',\n",
    "    'present',\n",
    "    'spend',\n",
    "    'talk',\n",
    "    'creative',\n",
    "    'tell',\n",
    "    'cost',\n",
    "    'drive',\n",
    "    'green',\n",
    "    'support',\n",
    "    'glad',\n",
    "    'remove',\n",
    "    'return',\n",
    "    'run',\n",
    "    'complex',\n",
    "    'due',\n",
    "    'effective',\n",
    "    'middle',\n",
    "    'regular',\n",
    "    'reserve',\n",
    "    'independent',\n",
    "    'leave',\n",
    "    'original',\n",
    "    'reach',\n",
    "    'rest',\n",
    "    'serve',\n",
    "    'watch',\n",
    "    'beautiful',\n",
    "    'charge',\n",
    "    'active',\n",
    "    'break',\n",
    "    'negative',\n",
    "    'safe',\n",
    "    'stay',\n",
    "    'visit',\n",
    "    'visual',\n",
    "    'affect',\n",
    "    'cover',\n",
    "    'report',\n",
    "    'rise',\n",
    "    'walk',\n",
    "    'white',\n",
    "    'beyond',\n",
    "    'junior',\n",
    "    'pick',\n",
    "    'unique',\n",
    "    'anything',\n",
    "    'classic',\n",
    "    'final',\n",
    "    'lift',\n",
    "    'mix',\n",
    "    'private',\n",
    "    'stop',\n",
    "    'teach',\n",
    "    'western',\n",
    "    'concern',\n",
    "    'familiar',\n",
    "    'fly',\n",
    "    'official',\n",
    "    'broad',\n",
    "    'comfortable',\n",
    "    'gain',\n",
    "    'maybe',\n",
    "    'rich',\n",
    "    'save',\n",
    "    'stand',\n",
    "    'young',\n",
    "    'heavy',\n",
    "    'hello',\n",
    "    'lead',\n",
    "    'listen',\n",
    "    'valuable',\n",
    "    'worry',\n",
    "    'handle',\n",
    "    'leading',\n",
    "    'meet',\n",
    "    'release',\n",
    "    'sell',\n",
    "    'finish',\n",
    "    'normal',\n",
    "    'press',\n",
    "    'ride',\n",
    "    'secret',\n",
    "    'spread',\n",
    "    'spring',\n",
    "    'tough',\n",
    "    'wait',\n",
    "    'brown',\n",
    "    'deep',\n",
    "    'display',\n",
    "    'flow',\n",
    "    'hit',\n",
    "    'objective',\n",
    "    'shoot',\n",
    "    'touch',\n",
    "    'cancel',\n",
    "    'chemical',\n",
    "    'cry',\n",
    "    'dump',\n",
    "    'extreme',\n",
    "    'push',\n",
    "    'conflict',\n",
    "    'eat',\n",
    "    'fill',\n",
    "    'formal',\n",
    "    'jump',\n",
    "    'kick',\n",
    "    'opposite',\n",
    "    'pass',\n",
    "    'pitch',\n",
    "    'remote',\n",
    "    'total',\n",
    "    'treat',\n",
    "    'vast',\n",
    "    'abuse',\n",
    "    'beat',\n",
    "    'burn',\n",
    "    'deposit',\n",
    "    'print',\n",
    "    'raise',\n",
    "    'sleep',\n",
    "    'somewhere',\n",
    "    'advance',\n",
    "    'anywhere',\n",
    "    'consist',\n",
    "    'dark',\n",
    "    'double',\n",
    "    'draw',\n",
    "    'equal',\n",
    "    'fix',\n",
    "    'hire',\n",
    "    'internal',\n",
    "    'join',\n",
    "    'kill',\n",
    "    'sensitive',\n",
    "    'tap',\n",
    "    'win',\n",
    "    'attack',\n",
    "    'claim',\n",
    "    'constant',\n",
    "    'drag',\n",
    "    'drink',\n",
    "    'guess',\n",
    "    'minor',\n",
    "    'pull',\n",
    "    'raw',\n",
    "    'soft',\n",
    "    'solid',\n",
    "    'wear',\n",
    "    'weird',\n",
    "    'wonder',\n",
    "    'annual',\n",
    "    'count',\n",
    "    'dead',\n",
    "    'doubt',\n",
    "    'feed',\n",
    "    'forever',\n",
    "    'impress',\n",
    "    'nobody',\n",
    "    'repeat',\n",
    "    'round',\n",
    "    'sing',\n",
    "    'slide',\n",
    "    'strip',\n",
    "    'whereas',\n",
    "    'wish',\n",
    "    'combine',\n",
    "    'command',\n",
    "    'dig',\n",
    "    'divide',\n",
    "    'equivalent',\n",
    "    'hang',\n",
    "    'hunt',\n",
    "    'initial',\n",
    "    'march',\n",
    "    'mention',\n",
    "    'spiritual',\n",
    "    'survey',\n",
    "    'tie',\n",
    "    'adult',\n",
    "    'brief',\n",
    "    'crazy',\n",
    "    'escape',\n",
    "    'gather',\n",
    "    'hate',\n",
    "    'prior',\n",
    "    'repair',\n",
    "    'rough',\n",
    "    'sad',\n",
    "    'scratch',\n",
    "    'sick',\n",
    "    'strike',\n",
    "    'employ',\n",
    "    'external',\n",
    "    'hurt',\n",
    "    'illegal',\n",
    "    'laugh',\n",
    "    'lay',\n",
    "    'mobile',\n",
    "    'nasty',\n",
    "    'ordinary',\n",
    "    'respond',\n",
    "    'royal',\n",
    "    'senior',\n",
    "    'split',\n",
    "    'strain',\n",
    "    'struggle',\n",
    "    'swim',\n",
    "    'train',\n",
    "    'upper',\n",
    "    'wash',\n",
    "    'yellow',\n",
    "    'convert',\n",
    "    'crash',\n",
    "    'dependent',\n",
    "    'fold',\n",
    "    'funny',\n",
    "    'grab',\n",
    "    'hide',\n",
    "    'miss',\n",
    "    'permit',\n",
    "    'quote',\n",
    "    'recover',\n",
    "    'resolve',\n",
    "    'roll',\n",
    "    'sink',\n",
    "    'slip',\n",
    "    'spare',\n",
    "    'suspect',\n",
    "    'sweet',\n",
    "    'swing',\n",
    "    'twist',\n",
    "    'upstairs',\n",
    "    'usual',\n",
    "    'abroad',\n",
    "    'brave',\n",
    "    'calm',\n",
    "    'concentrate',\n",
    "    'estimate',\n",
    "    'grand',\n",
    "    'male',\n",
    "    'mine',\n",
    "    'prompt',\n",
    "    'quiet',\n",
    "    'refuse',\n",
    "    'regret',\n",
    "    'reveal',\n",
    "    'rush',\n",
    "    'shake',\n",
    "    'shift',\n",
    "    'shine',\n",
    "    'steal',\n",
    "    'suck',\n",
    "    'surround',\n",
    "    'anybody',\n",
    "    'bear',\n",
    "    'brilliant',\n",
    "    'dare',\n",
    "    'dear',\n",
    "    'delay',\n",
    "    'drunk',\n",
    "    'female',\n",
    "    'hurry',\n",
    "    'inevitable',\n",
    "    'invite',\n",
    "    'kiss',\n",
    "    'neat',\n",
    "    'pop',\n",
    "    'punch',\n",
    "    'quit',\n",
    "    'reply',\n",
    "    'representative',\n",
    "    'resist',\n",
    "    'rip',\n",
    "    'rub',\n",
    "    'silly',\n",
    "    'smile',\n",
    "    'spell',\n",
    "    'stretch',\n",
    "    'stupid',\n",
    "    'tear',\n",
    "    'temporary',\n",
    "    'tomorrow',\n",
    "    'wake',\n",
    "    'wrap',\n",
    "    'yesterday']\n",
    "s1 = []\n",
    "s2 = []\n",
    "s3 = []\n",
    "s4 = []\n",
    "s5 = []\n",
    "s6 = []\n",
    "s1_s6 = []\n",
    "#print(\" \".join([nouns[random.randrange(0, len(nouns))] for i in range(4)]))\n",
    "for a in range(len(nouns)):\n",
    "    count = syllable_count(nouns[a])\n",
    "    if count == 1:\n",
    "        s1.append(nouns[a])\n",
    "    if count == 2:\n",
    "        s2.append(nouns[a])\n",
    "    if count == 3:\n",
    "        s3.append(nouns[a])\n",
    "    if count == 4:\n",
    "        s4.append(nouns[a])\n",
    "    if count == 5:\n",
    "        s5.append(nouns[a])\n",
    "    if count == 6:\n",
    "        s6.append(nouns[a])\n",
    "s1_s6.append(s1)\n",
    "s1_s6.append(s2)\n",
    "s1_s6.append(s3)\n",
    "s1_s6.append(s4)\n",
    "s1_s6.append(s5)\n",
    "s1_s6.append(s6)\n",
    "print(len(nouns),'(total) /',len(s1_s6),'(type) /',len(s1),'(s1) /',len(s2),'(s2) /',len(s3),'(s3) /',len(s4),'(s4) /',len(s5),'(s5) /',len(s6),'(s6)')\n",
    "print('s1 =',s1)\n",
    "print('s2 =',s2)\n",
    "print('s3 =',s3)\n",
    "print('s4 =',s4)\n",
    "print('s5 =',s5)\n",
    "print('s6 =',s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elevator'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根據音節數，到特定的音節陣列中隨機挑選\n",
    "c = 4\n",
    "random.choice(s1_s6[c-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     D:\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "syns: good.n.01\n",
      "32\n",
      "['in_effect', 'near', 'just', 'expert', 'good', 'salutary', 'sound', 'beneficial', 'skilful', 'safe', 'unspoiled', 'proficient', 'effective', 'upright', 'honest', 'adept', 'well', 'practiced', 'dear', 'estimable', 'full', 'right', 'ripe', 'undecomposed', 'serious', 'skillful', 'secure', 'dependable', 'unspoilt', 'respectable', 'honorable', 'in_force']\n"
     ]
    }
   ],
   "source": [
    "# 搜尋詞語的同義詞(使用NLTK)\n",
    "nltk.download('wordnet')\n",
    "synonyms = []\n",
    "word = \"good\"\n",
    "syns = wordnet.synsets(word)[0].name()\n",
    "print('syns:',syns)\n",
    "for syn in wordnet.synsets(word,pos='a'): # pos可指定詞性\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "synonyms2 = list(set(synonyms))\n",
    "print(len(synonyms2))\n",
    "print(synonyms2) # 用set()把重複的去除掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['effective.s.04', 'approach.v.01', 'just.a.01', 'expert.n.01', 'good.n.01', 'good.s.18', 'sound.n.01', 'beneficial.s.01', 'adept.s.01', 'safe.n.01', 'good.s.20', 'adept.s.01', 'effective.a.01', 'upright.n.01', 'honest.a.01', 'ace.n.03', 'well.n.01', 'practice.v.01', 'beloved.n.01', 'estimable.a.01', 'full_moon.n.01', 'right.n.01', 'ripe.a.01', 'good.s.20', 'serious.a.01', 'adept.s.01', 'procure.v.01', 'reliable.a.01', 'good.s.20', 'respectable.a.01', 'honest.a.01', 'effective.s.04']\n"
     ]
    }
   ],
   "source": [
    "# 找相似詞語的wordnet\n",
    "lst_syns = []\n",
    "for k in range(len(synonyms2)):\n",
    "    a = synonyms2[k]\n",
    "    b = wordnet.synsets(a)[0].name()\n",
    "    #print(b)\n",
    "    lst_syns.append(b)\n",
    "print(lst_syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, 0.16666666666666666, 1.0, None, 0.46153846153846156, None, None, 0.11764705882352941, None, None, None, 0.11764705882352941, None, 0.15384615384615385, 0.14285714285714285, None, 0.15384615384615385, None, 0.5333333333333333, 0.25, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "# 相似詞語跟原始詞語的相似性計算\n",
    "lst_sim = []\n",
    "for w in range(len(lst_syns)):\n",
    "    cb = wordnet.synset(syns)\n",
    "    ib = wordnet.synset(lst_syns[w])\n",
    "    sim = cb.wup_similarity(ib)\n",
    "    lst_sim.append(sim)\n",
    "print(lst_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alive', 'animate', 'breathing', 'living', 'aware', 'conscious', 'vital']\n"
     ]
    }
   ],
   "source": [
    "# 透過爬蟲方式找相似詞語\n",
    "def synonyms(word):\n",
    "    url = \"https://www.thesaurus.com/browse/\"\n",
    "    url += word\n",
    "    #print(url)\n",
    "    r = requests.get(url)\n",
    "    soup = bs(r.content, \"html.parser\")\n",
    "    answer_list = soup.find(\"ul\",'css-17d6qyx-WordGridLayoutBox et6tpn80')\n",
    "    syns = answer_list.findChildren(\"a\")\n",
    "    #print(syns)\n",
    "    lst = []\n",
    "    for i in range(len(syns)):\n",
    "        lst.append(syns[i].text)\n",
    "    return print(lst)\n",
    "synonyms_output = synonyms(\"lived\")\n",
    "synonyms_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original word: live\n",
      "crawl list: ['alive', 'animate', 'breathing', 'living', 'aware', 'conscious', 'vital']\n",
      "correct syllable count: 1\n",
      "alive 2\n",
      "animate 3\n",
      "breathing 2\n",
      "living 2\n",
      "aware 2\n",
      "conscious 2\n",
      "vital 2\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer() \n",
    "w = tmp_wo[7] # 沒有對齊到的詞語\n",
    "w = ps.stem(w)\n",
    "print('original word:',w)\n",
    "lst_syn = synonyms(w)\n",
    "print('crawl list:',lst_syn)\n",
    "s = tmp_so[7] # 正確的音節數量\n",
    "print('correct syllable count:',s)\n",
    "for n in range(len(lst_syn)):\n",
    "    print(lst_syn[n],syllable_count(lst_syn[n]))\n",
    "    if syllable_count(lst_syn[n]) == s:\n",
    "        print(lst_syn[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.05468750e-01,  4.19921875e-02, -9.94873047e-03,  7.22656250e-02,\n",
       "        1.31835938e-01, -5.22460938e-02,  4.49218750e-02,  3.27148438e-02,\n",
       "       -1.12915039e-02,  2.44140625e-01,  1.52343750e-01, -2.48046875e-01,\n",
       "       -2.61718750e-01,  7.32421875e-02,  2.30712891e-02, -1.65039062e-01,\n",
       "        3.75000000e-01,  3.33984375e-01, -3.54003906e-02,  4.88281250e-02,\n",
       "       -2.63671875e-01,  1.95312500e-03, -2.06054688e-01, -1.67968750e-01,\n",
       "        2.31445312e-01, -2.50000000e-01, -6.44531250e-02,  1.48437500e-01,\n",
       "        4.95605469e-02, -1.66992188e-01, -1.15356445e-02, -9.57031250e-02,\n",
       "       -1.02050781e-01,  6.59179688e-02, -1.73339844e-02, -8.17871094e-03,\n",
       "        3.32031250e-01, -2.71484375e-01, -2.22656250e-01,  2.73437500e-01,\n",
       "       -6.39648438e-02,  1.82617188e-01,  5.49316406e-03, -1.16210938e-01,\n",
       "       -1.73568726e-04,  1.07421875e-01, -7.66601562e-02, -1.89453125e-01,\n",
       "       -2.47070312e-01, -1.89453125e-01,  5.63964844e-02, -2.59765625e-01,\n",
       "        3.19824219e-02, -8.00781250e-02, -9.22851562e-02, -3.57421875e-01,\n",
       "       -1.62109375e-01, -4.85839844e-02,  7.51953125e-02, -2.59765625e-01,\n",
       "        1.64062500e-01,  2.33398438e-01,  1.33789062e-01, -3.61328125e-02,\n",
       "       -1.35742188e-01, -1.28784180e-02,  4.82177734e-03, -1.04370117e-02,\n",
       "       -2.18750000e-01, -6.68945312e-02,  3.55468750e-01, -4.88281250e-02,\n",
       "       -1.88476562e-01, -4.27246094e-03, -1.49414062e-01,  3.63769531e-02,\n",
       "       -1.76757812e-01, -1.58203125e-01,  3.11279297e-02,  2.43164062e-01,\n",
       "        9.81445312e-02,  1.43554688e-01, -2.14843750e-01, -1.20117188e-01,\n",
       "       -1.91406250e-01,  1.80664062e-01, -1.71875000e-01,  1.27929688e-01,\n",
       "        8.74023438e-02, -8.88671875e-02,  1.80664062e-01, -2.29492188e-01,\n",
       "       -1.21093750e-01, -5.12695312e-03, -1.45507812e-01,  9.81445312e-02,\n",
       "       -1.41601562e-01,  1.06933594e-01, -1.36718750e-02, -1.05957031e-01,\n",
       "       -2.24609375e-01,  3.61328125e-02,  3.83300781e-02,  1.14257812e-01,\n",
       "        6.20117188e-02, -2.55859375e-01,  7.81250000e-03,  7.47070312e-02,\n",
       "        1.50390625e-01, -1.42578125e-01, -5.81054688e-02,  8.11767578e-03,\n",
       "       -3.08837891e-02, -3.73535156e-02, -8.39843750e-02,  4.22363281e-02,\n",
       "       -2.00195312e-01, -3.97949219e-02,  2.14843750e-01, -7.91015625e-02,\n",
       "        6.40869141e-03,  1.43554688e-01,  5.82885742e-03,  1.04003906e-01,\n",
       "       -1.04003906e-01,  2.73437500e-01,  2.00195312e-01, -2.94921875e-01,\n",
       "       -3.20312500e-01,  1.04980469e-01,  1.08886719e-01, -1.54296875e-01,\n",
       "        6.49414062e-02, -6.03027344e-02, -1.61132812e-01, -2.69531250e-01,\n",
       "       -5.71289062e-02, -6.83593750e-02, -2.28271484e-02,  3.24218750e-01,\n",
       "       -2.46093750e-01,  9.76562500e-02, -1.09863281e-01,  9.13085938e-02,\n",
       "        1.14746094e-01,  1.69921875e-01, -1.23535156e-01,  4.57763672e-03,\n",
       "       -2.12890625e-01, -1.93359375e-01,  8.00781250e-02,  5.93261719e-02,\n",
       "        5.59082031e-02,  1.19628906e-01, -1.62109375e-01,  1.61132812e-01,\n",
       "       -1.52343750e-01, -9.94873047e-03,  1.64062500e-01, -3.16406250e-01,\n",
       "        5.66406250e-02,  3.49609375e-01,  1.70898438e-01,  8.91113281e-03,\n",
       "        2.00195312e-01,  5.46875000e-02, -1.91650391e-02,  6.22558594e-02,\n",
       "       -1.08642578e-02,  5.20019531e-02, -1.54296875e-01,  1.47094727e-02,\n",
       "        1.07910156e-01, -1.23535156e-01,  6.17675781e-02,  2.75390625e-01,\n",
       "        7.42187500e-02,  2.48046875e-01,  1.99218750e-01,  2.20703125e-01,\n",
       "       -2.20947266e-02,  8.69140625e-02,  1.57470703e-02,  6.39648438e-02,\n",
       "        2.27539062e-01, -3.28125000e-01,  2.02148438e-01,  1.17187500e-01,\n",
       "       -8.69140625e-02,  2.67578125e-01,  1.86523438e-01,  7.86132812e-02,\n",
       "        4.58984375e-01,  1.32812500e-01, -2.68554688e-02,  4.70703125e-01,\n",
       "        1.06811523e-02,  4.56542969e-02,  1.59179688e-01, -4.39453125e-02,\n",
       "        4.95605469e-02, -3.85742188e-02,  2.08007812e-01, -8.69140625e-02,\n",
       "       -1.17187500e-01, -2.45117188e-01,  4.58984375e-02, -4.12597656e-02,\n",
       "        1.61132812e-01, -1.94335938e-01, -1.44531250e-01, -3.06396484e-02,\n",
       "       -9.03320312e-02, -1.14135742e-02, -1.41601562e-02, -1.13769531e-01,\n",
       "       -1.00585938e-01,  1.68457031e-02, -2.63671875e-01, -2.41210938e-01,\n",
       "       -1.33789062e-01,  1.28906250e-01,  2.29492188e-02, -1.25976562e-01,\n",
       "        2.36328125e-01, -9.65118408e-04,  2.28515625e-01,  1.50390625e-01,\n",
       "       -4.39453125e-01, -4.02832031e-02,  4.12597656e-02, -2.25585938e-01,\n",
       "        2.45117188e-01,  3.31115723e-03,  1.62109375e-01,  9.22851562e-02,\n",
       "       -4.22363281e-02, -2.20703125e-01, -4.39453125e-02, -2.05078125e-01,\n",
       "        1.87500000e-01, -2.25585938e-01, -6.00585938e-02, -3.56445312e-02,\n",
       "       -1.20239258e-02,  2.53906250e-01,  4.61425781e-02,  4.95605469e-02,\n",
       "        8.85009766e-03, -9.76562500e-02, -3.12500000e-02,  2.24609375e-01,\n",
       "        3.61328125e-02,  4.43359375e-01,  1.49414062e-01,  3.51562500e-02,\n",
       "       -3.32031250e-01,  4.97436523e-03, -3.80859375e-02, -8.85009766e-03,\n",
       "       -1.70898438e-01, -1.28906250e-01,  2.08007812e-01,  2.11914062e-01,\n",
       "        1.74804688e-01,  3.78906250e-01,  4.24804688e-02, -1.08886719e-01,\n",
       "        5.90820312e-02, -1.17675781e-01,  1.69921875e-01,  2.80761719e-02,\n",
       "       -5.73730469e-02, -6.29882812e-02,  2.85156250e-01, -2.30468750e-01,\n",
       "       -2.87109375e-01,  4.00390625e-02,  9.17968750e-02, -3.65234375e-01,\n",
       "        2.42187500e-01, -4.00390625e-02,  1.37939453e-02,  1.95312500e-01,\n",
       "        6.54296875e-02, -2.13867188e-01, -8.00781250e-02,  1.15722656e-01,\n",
       "       -4.37500000e-01,  2.10937500e-01, -4.60937500e-01,  7.03125000e-02,\n",
       "       -2.83203125e-01,  3.41796875e-01, -9.57031250e-02, -7.22656250e-02,\n",
       "       -8.39843750e-02, -3.22265625e-01,  2.75390625e-01, -2.07031250e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('model/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "model.wv['lived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-bcf048eb238e>\", line 1, in <module>\n",
      "    model.similar_by_word('lived', topn=10)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\", line 417, in similar_by_word\n",
      "    return self.most_similar(positive=[word], topn=topn, restrict_vocab=restrict_vocab)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\", line 348, in most_similar\n",
      "    self.init_sims()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\", line 1053, in init_sims\n",
      "    self.vectors_norm = (self.vectors / sqrt((self.vectors ** 2).sum(-1))[..., newaxis]).astype(REAL)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\Anaconda3\\lib\\inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\Anaconda3\\lib\\inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\Anaconda3\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"D:\\Anaconda3\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"D:\\Anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"D:\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "model.similar_by_word('lived', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model.most_similar('lived')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     1,
     3,
     5,
     9,
     13,
     17,
     22,
     77,
     80,
     87
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2fd11e332634>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneratePoem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msyllableCounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msourceText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-2fd11e332634>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0msyllableCounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'5,7,5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneratePoem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msyllableCounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msourceText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-2fd11e332634>\u001b[0m in \u001b[0;36mgeneratePoem\u001b[1;34m(syllableCounts, sourceText, cache)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerateLine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrorMessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-2fd11e332634>\u001b[0m in \u001b[0;36mgenerateLine\u001b[1;34m(syllables, text_model)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerateLine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msyllables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0msyls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetSyllables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\markovify\\text.py\u001b[0m in \u001b[0;36mmake_sentence\u001b[1;34m(self, init_state, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m             \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmax_words\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\markovify\\chain.py\u001b[0m in \u001b[0;36mwalk\u001b[1;34m(self, init_state)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\markovify\\chain.py\u001b[0m in \u001b[0;36mgen\u001b[1;34m(self, init_state)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnext_word\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEND\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mnext_word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnext_word\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# https://github.com/danyalette/markov-poem\n",
    "def makeId(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\n",
    "def getSourceCacheId(cacheIndex, source):\n",
    "    cacheId = None\n",
    "    for i in cacheIndex:\n",
    "        if i[0] == source:\n",
    "            cacheId = i[1]\n",
    "    return cacheId\n",
    "def removeDuplicateCachedModels(cacheIndex, source):\n",
    "    for i in cacheIndex:\n",
    "        if i[0] == source:\n",
    "            cacheIndex.remove(i)\n",
    "def writeJson(fileHandle, jsonString):\n",
    "    # 解決unicode錯誤問題：https://zhidao.baidu.com/question/309967670532246284.html\n",
    "    #return fileHandle.write(unicode(json.dumps(jsonString, ensure_ascii=False)))\n",
    "    return fileHandle.write(json.dumps(jsonString, ensure_ascii=False))\n",
    "def openFile(path, mode, isRelative = True):\n",
    "    if isRelative:\n",
    "        currentDir = os.path.dirname('test.txt')\n",
    "        path = os.path.join(currentDir, path)\n",
    "    return io.open(path,mode,encoding='utf-8')\n",
    "def generatePoem(syllableCounts, sourceText, cache):\n",
    "\n",
    "    result = []\n",
    "    syllableCounts = syllableCounts.split(',')\n",
    "\n",
    "    if not os.path.isfile(sourceText):\n",
    "        throwUsageError()\n",
    "    if not syllableCounts or [s for s in syllableCounts if not s.isdigit()]:\n",
    "        throwUsageError()\n",
    "\n",
    "    # get list of cached sources\n",
    "\n",
    "    with openFile('data/sources.json', 'r') as f:\n",
    "        text = f.read()\n",
    "        if text != '':\n",
    "            sourceModelIndex = json.loads(text)\n",
    "        else:\n",
    "            sourceModelIndex = []\n",
    "\n",
    "    # get id of current source's cachec\n",
    "    sourceCacheId = getSourceCacheId(sourceModelIndex, sourceText)\n",
    "\n",
    "    # if ww to use cache, and current source is cached:\n",
    "    if cache and sourceCacheId:\n",
    "        with openFile('data/' + sourceCacheId + '.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            text_model = markovify.Text.from_json(data)\n",
    "    else:\n",
    "        with openFile(sourceText, 'r', False) as f:\n",
    "            text = f.read()\n",
    "        text_model = markovify.Text(text)\n",
    "        model_json = text_model.to_json()\n",
    "\n",
    "        # save new markov model to cache\n",
    "        sourceId = makeId()\n",
    "        with openFile('data/sources.json', 'w') as indexFile:\n",
    "            removeDuplicateCachedModels(sourceModelIndex, sourceText)\n",
    "            sourceModelIndex.append((sourceText,sourceId))\n",
    "            writeJson(indexFile, sourceModelIndex)\n",
    "        with openFile('data/' + sourceId + '.json', 'w') as outFile:\n",
    "            writeJson(outFile, model_json)\n",
    "\n",
    "    for s in syllableCounts:\n",
    "        errorMessage = '[Error generating line with length ' + s + ']'\n",
    "        if int(s) > 2 and int(s) < 15:\n",
    "            line = None\n",
    "            i = 0\n",
    "            while not line and i < 10:\n",
    "                line = generateLine(int(s), text_model)\n",
    "            if not line:\n",
    "                line = errorMessage\n",
    "        else:\n",
    "            line = errorMessage\n",
    "        result.append(line)\n",
    "    return '\\n'.join(result)\n",
    "def throwUsageError():\n",
    "    print('Usage: python markov_poem.py -f <source_text_filepath> -s <comma,separated,syllable,count> [-c (use cached markov model of source text)]')\n",
    "    sys.exit()\n",
    "def generateLine(syllables, text_model):\n",
    "    for i in range(300):\n",
    "        sentence = text_model.make_sentence()\n",
    "        if (sentence):\n",
    "            syls = getSyllables(sentence)\n",
    "            if (syls == syllables):\n",
    "                return sentence[:-1]\n",
    "def main():\n",
    "    sourceText = 'test.txt'\n",
    "    syllableCounts = '5,7,5'\n",
    "    cache = False\n",
    "    print(generatePoem(syllableCounts, sourceText, cache))\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "code_folding": [
     1,
     3,
     20
    ]
   },
   "outputs": [],
   "source": [
    "# 計算音節數量\n",
    "def count_syllables(word):\n",
    "    return len(re.findall('(?!e$)[aeiouy]+', word, re.I) + re.findall('^[^aeiouy]*e$', word, re.I))\n",
    "def syllable_count(word):\n",
    "    word = word.lower()\n",
    "    punc = string.punctuation\n",
    "    count = 0\n",
    "    vowels = \"aeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith(\"e\"):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    if word in punc: # 如果詞語是標點符號，音節數量則為0\n",
    "        count = 0\n",
    "    return count\n",
    "def sylco(word) :\n",
    "    word = word.lower()\n",
    "    # exception_add are words that need extra syllables\n",
    "    # exception_del are words that need less syllables\n",
    "    exception_add = ['serious','crucial']\n",
    "    exception_del = ['fortunately','unfortunately']\n",
    "    co_one = ['cool','coach','coat','coal','count','coin','coarse','coup','coif','cook','coign','coiffe','coof','court']\n",
    "    co_two = ['coapt','coed','coinci']\n",
    "    pre_one = ['preach']\n",
    "    syls = 0 #added syllable number\n",
    "    disc = 0 #discarded syllable number\n",
    "    #1) if letters < 3 : return 1\n",
    "    if len(word) <= 3 :\n",
    "        syls = 1\n",
    "        return syls\n",
    "    #2) if doesn't end with \"ted\" or \"tes\" or \"ses\" or \"ied\" or \"ies\", discard \"es\" and \"ed\" at the end.\n",
    "    # if it has only 1 vowel or 1 set of consecutive vowels, discard. (like \"speed\", \"fled\" etc.)\n",
    "    if word[-2:] == \"es\" or word[-2:] == \"ed\" :\n",
    "        doubleAndtripple_1 = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "        if doubleAndtripple_1 > 1 or len(re.findall(r'[eaoui][^eaoui]',word)) > 1 :\n",
    "            if word[-3:] == \"ted\" or word[-3:] == \"tes\" or word[-3:] == \"ses\" or word[-3:] == \"ied\" or word[-3:] == \"ies\" :\n",
    "                pass\n",
    "            else :\n",
    "                disc+=1\n",
    "    #3) discard trailing \"e\", except where ending is \"le\"  \n",
    "    le_except = ['whole','mobile','pole','male','female','hale','pale','tale','sale','aisle','whale','while']\n",
    "    if word[-1:] == \"e\" :\n",
    "        if word[-2:] == \"le\" and word not in le_except :\n",
    "            pass\n",
    "        else :\n",
    "            disc+=1\n",
    "    #4) check if consecutive vowels exists, triplets or pairs, count them as one.\n",
    "    doubleAndtripple = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "    tripple = len(re.findall(r'[eaoui][eaoui][eaoui]',word))\n",
    "    disc+=doubleAndtripple + tripple\n",
    "    #5) count remaining vowels in word.\n",
    "    numVowels = len(re.findall(r'[eaoui]',word))\n",
    "    #6) add one if starts with \"mc\"\n",
    "    if word[:2] == \"mc\" :\n",
    "        syls+=1\n",
    "    #7) add one if ends with \"y\" but is not surrouned by vowel\n",
    "    if word[-1:] == \"y\" and word[-2] not in \"aeoui\" :\n",
    "        syls +=1\n",
    "    #8) add one if \"y\" is surrounded by non-vowels and is not in the last word.\n",
    "    for i,j in enumerate(word) :\n",
    "        if j == \"y\" :\n",
    "            if (i != 0) and (i != len(word)-1) :\n",
    "                if word[i-1] not in \"aeoui\" and word[i+1] not in \"aeoui\" :\n",
    "                    syls+=1\n",
    "    #9) if starts with \"tri-\" or \"bi-\" and is followed by a vowel, add one.\n",
    "    if word[:3] == \"tri\" and word[3] in \"aeoui\" :\n",
    "        syls+=1\n",
    "    if word[:2] == \"bi\" and word[2] in \"aeoui\" :\n",
    "        syls+=1\n",
    "    #10) if ends with \"-ian\", should be counted as two syllables, except for \"-tian\" and \"-cian\"\n",
    "    if word[-3:] == \"ian\" : \n",
    "    #and (word[-4:] != \"cian\" or word[-4:] != \"tian\") :\n",
    "        if word[-4:] == \"cian\" or word[-4:] == \"tian\" :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "    #11) if starts with \"co-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "    if word[:2] == \"co\" and word[2] in 'eaoui' :\n",
    "        if word[:4] in co_two or word[:5] in co_two or word[:6] in co_two :\n",
    "            syls+=1\n",
    "        elif word[:4] in co_one or word[:5] in co_one or word[:6] in co_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "    #12) if starts with \"pre-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "    if word[:3] == \"pre\" and word[3] in 'eaoui' :\n",
    "        if word[:6] in pre_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "    #13) check for \"-n't\" and cross match with dictionary to add syllable.\n",
    "    negative = [\"doesn't\", \"isn't\", \"shouldn't\", \"couldn't\",\"wouldn't\"]\n",
    "    if word[-3:] == \"n't\" :\n",
    "        if word in negative :\n",
    "            syls+=1\n",
    "        else :\n",
    "            pass   \n",
    "    #14) Handling the exceptional words.\n",
    "    if word in exception_del :\n",
    "        disc+=1\n",
    "    if word in exception_add :\n",
    "        syls+=1     \n",
    "    # calculate the output\n",
    "    return numVowels - disc + syls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word = \",\"\n",
    "print(count_syllables(word))\n",
    "print(syllable_count(word))\n",
    "print(sylco(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sadly, more downs than ups.\n",
      "The plot was pretty decent.\n"
     ]
    }
   ],
   "source": [
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "data = 'Sadly, more downs than ups. The plot was pretty decent.'\n",
    "for row in sent_tokenizer.tokenize(data):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
